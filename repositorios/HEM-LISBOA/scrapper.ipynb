{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper para o site da Hemeroteca Digital de Lisboa\n",
    "\n",
    "Esse notebook busca coletar os dados dos periódicos digitalizados e disponíveis no site da Hemeroteca Digital de Lisboa. Os dados serão organizados em um *dataframe* e exportados para um arquivo csv.\n",
    "\n",
    "Os dados coletados são:\n",
    "\n",
    "- **Título**: Título do periódico\n",
    "- **Autoria**: Autoria do periódico\n",
    "- **Período**: Período disponível do periódico\n",
    "- **Link**: Link para o periódico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar bibliotecas\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir lista de letras que foram o índice\n",
    "letras = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J','L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U','V', 'X', 'Z']\n",
    "\n",
    "# definir url base\n",
    "url_base = 'https://hemerotecadigital.cm-lisboa.pt/Indice/Indice'\n",
    "\n",
    "# final da url\n",
    "url_final = '.htm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceA.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceB.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceC.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceD.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceE.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceF.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceG.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceH.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceI.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceJ.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceL.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceM.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceN.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceO.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceP.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceQ.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceR.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceS.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceT.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceU.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceV.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceX.htm', 'https://hemerotecadigital.cm-lisboa.pt/Indice/IndiceZ.htm']\n"
     ]
    }
   ],
   "source": [
    "# definir lista de urls completa\n",
    "urls = [url_base + letra + url_final for letra in letras]\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para criar objeto soup\n",
    "def criar_soup(url):\n",
    "    html = requests.get(url)\n",
    "    soup = bs(html.content, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all a href that ends with .htm and start with ../Periodicos or ../OBRAS\n",
    "def encontrar_links(soup):\n",
    "    links = soup.find_all('a', href=True)\n",
    "    links = [link['href'] for link in links if link['href'].endswith('.htm') and (link['href'].startswith('../Periodicos') or link['href'].startswith('../OBRAS'))]\n",
    "    # replace ../ with https://hemerotecadigital.cm-lisboa.pt/\n",
    "    links = [link.replace('../', 'https://hemerotecadigital.cm-lisboa.pt/') for link in links]\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop com as urls\n",
    "links_geral = []\n",
    "for url in urls:\n",
    "    soup = criar_soup(url)\n",
    "    links = encontrar_links(soup)\n",
    "    links_geral.extend(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para pegar o título e a data de publicação\n",
    "def pegar_titulo_data(soup):\n",
    "    titulo_data = soup.find('title').text\n",
    "    # encontrar data com regex: tudo entre [ e ]\n",
    "    # se não encontrar [ no título, retorna None\n",
    "    pattern = r'\\['\n",
    "    if re.search(pattern, titulo_data) == None:\n",
    "        data = \"Sem data\"\n",
    "        titulo = titulo_data\n",
    "    else:\n",
    "        data = re.findall(r'\\[(.*?)\\]', titulo_data)\n",
    "        # encontrar título com regex: tudo antes de [\n",
    "        titulo = re.findall(r'(.*?)\\[', titulo_data)\n",
    "    return titulo, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all link that ends with .pdf\n",
    "def encontrar_pdf(soup, url):\n",
    "    pdf_links = soup.find_all('a', href=True)\n",
    "    pdf_links = [link['href'] for link in pdf_links if link['href'].endswith('.pdf') or link['href'].endswith('.PDF')]\n",
    "    # excluir string após última \"/\" em url\n",
    "    url = url.rsplit('/', 1)[0]\n",
    "    url = url + '/'\n",
    "    # add url to pdf_links\n",
    "    pdf_links = [url + link for link in pdf_links]\n",
    "    return pdf_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar lista geral para os dados\n",
    "dados_geral = []\n",
    "# loop nos links\n",
    "for link in links_geral:\n",
    "    soup = criar_soup(link)\n",
    "    titulo, data = pegar_titulo_data(soup)\n",
    "    pdf_links = encontrar_pdf(soup, link)\n",
    "    # se FichasHistoricas estiver no link, adicionar à lista de dados na variável fichas\n",
    "    fichas = \"Sem Ficha Histórica\"\n",
    "    if any(\"FichasHistoricas\" in pdf for pdf in pdf_links):\n",
    "        fichas = [pdf for pdf in pdf_links if \"FichasHistoricas\" in pdf]\n",
    "        # correção do link para o pdf\n",
    "        fichas = fichas[0].replace(link, 'https://hemerotecadigital.cm-lisboa.pt/')\n",
    "    # contar o número de pdfs\n",
    "    num_pdfs = len(pdf_links)\n",
    "    # verificar se algum pdf possui a string\"FichasHistoricas\"\n",
    "    # se sim, excluir da lista e subtrair 1 do número de pdfs\n",
    "    if any(\"FichasHistoricas\" in pdf for pdf in pdf_links):\n",
    "        pdf_links = [pdf for pdf in pdf_links if \"FichasHistoricas\" not in pdf]\n",
    "        num_pdfs = num_pdfs - 1\n",
    "    # criar lista com os dados\n",
    "    dados = [titulo, data, num_pdfs, pdf_links, fichas]\n",
    "    # adicionar dados à lista de dados\n",
    "    dados_geral.append(dados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar dataframe com headers\n",
    "df = pd.DataFrame(dados_geral, columns=['Título', 'Data', 'Quantidade de PDF', 'Links dos PDFs', 'Fichas Históricas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18163/591487736.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['Título'] = df['Título'].str.replace('[', '')\n",
      "/tmp/ipykernel_18163/591487736.py:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['Título'] = df['Título'].str.replace(']', '')\n"
     ]
    }
   ],
   "source": [
    "# transformar itens da coluna 'Título' em string\n",
    "df['Título'] = df['Título'].astype(str)\n",
    "# remover colchetes e aspas da coluna 'Título'\n",
    "df['Título'] = df['Título'].str.replace('[', '')\n",
    "df['Título'] = df['Título'].str.replace(']', '')\n",
    "df['Título'] = df['Título'].str.replace(\"'\", '')\n",
    "df['Título'] = df['Título'].str.replace('\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18163/3931564129.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['Data'] = df['Data'].str.replace('[', '')\n",
      "/tmp/ipykernel_18163/3931564129.py:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['Data'] = df['Data'].str.replace(']', '')\n"
     ]
    }
   ],
   "source": [
    "# transformar itens da coluna 'Data' em string\n",
    "df['Data'] = df['Data'].astype(str)\n",
    "# remover colchetes e aspas da coluna 'Data'\n",
    "df['Data'] = df['Data'].str.replace('[', '')\n",
    "df['Data'] = df['Data'].str.replace(']', '')\n",
    "df['Data'] = df['Data'].str.replace(\"'\", '')\n",
    "df['Data'] = df['Data'].str.replace('\"', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se coluna data for vazia, preencher com \"Sem data\"\n",
    "df['Data'] = df['Data'].replace('', 'Sem data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se links_pdf não for vazio, pegar o primeiro link\n",
    "if df['Links dos PDFs'].empty == False:\n",
    "    # se coluna 'Título' for vazia, preencher com item da coluna 'Links dos PDFs'\n",
    "    df.loc[df['Título'] == '', 'Título'] = df['Links dos PDFs'].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma itens da coluna 'Título' em string\n",
    "df['Título'] = df['Título'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18163/3298843525.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Título'] = df['Título'].str.replace(r'.*Periodicos/', '')\n",
      "/tmp/ipykernel_18163/3298843525.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Título'] = df['Título'].str.replace(r'.*OBRAS/', '')\n",
      "/tmp/ipykernel_18163/3298843525.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Título'] = df['Título'].str.replace(r'/.*', '')\n"
     ]
    }
   ],
   "source": [
    "# excluir string até \"Periodicos/\" ou \"OBRAS/\" na coluna título usando regex\n",
    "df['Título'] = df['Título'].str.replace(r'.*Periodicos/', '')\n",
    "df['Título'] = df['Título'].str.replace(r'.*OBRAS/', '')\n",
    "# substitui tudo após o primeiro \"/\" por vazio\n",
    "df['Título'] = df['Título'].str.replace(r'/.*', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se valor na coluna 'Título' for repetido, exclui linha\n",
    "df = df.drop_duplicates(subset=['Título'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tente encontrar '\\d{4}-\\d{4}' na coluna 'Data' senão encontrar busca por '\\d{4}'\n",
    "df['Anos'] = df['Data'].str.findall(r'\\d{4}-\\d{4}|\\d{4}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18163/3049931291.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Data'] = df['Data'].str.replace(r'\\d{4}-\\d{4}|\\d{4}', '')\n",
      "/tmp/ipykernel_18163/3049931291.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Data'] = df['Data'].str.replace(r';|\\?', '')\n"
     ]
    }
   ],
   "source": [
    "# deletar '\\d{4}-\\d{4}|\\d{4}' da coluna 'Data'\n",
    "df['Data'] = df['Data'].str.replace(r'\\d{4}-\\d{4}|\\d{4}', '')\n",
    "# deletar ';', '?', da coluna 'Data'\n",
    "df['Data'] = df['Data'].str.replace(r';|\\?', '')\n",
    "# deletar 'Sem data' da coluna 'Data'\n",
    "df['Data'] = df['Data'].str.replace(r'Sem data', '')\n",
    "# deletar espaços em branco da coluna 'Data'\n",
    "df['Data'] = df['Data'].str.strip()\n",
    "# adicionar 'Sem local' à coluna 'Data' se estiver vazia\n",
    "df['Data'] = df['Data'].replace('', 'Sem local')\n",
    "# renomear coluna 'Data' para 'Local'\n",
    "df = df.rename(columns={'Data': 'Local'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":warning: É preciso limpar com mais atenção a coluna 'Local'. Os dados são muito inconsistentes e não há um padrão claro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste se a string \", \" está na coluna 'Local'\n",
    "#try:\n",
    "#    df['Local'].str.contains(', ')\n",
    "#    df['Local'] = df['Local'].str.replace(r'.*, ', '')\n",
    "#    df['Local'] = df['Local'].str.replace(r',', '')\n",
    "#except:\n",
    "    # se não estiver, mantenha a coluna 'Local' como está\n",
    "#    df['Local'] = df['Local'].str.replace(r',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganizar colunas\n",
    "df = df[['Título', 'Anos', 'Local', 'Fichas Históricas', 'Quantidade de PDF', 'Links dos PDFs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvar dataframe em csv\n",
    "df.to_csv('hemeroteca_lisboa.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
