{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper para o site da Hemeroteca Digital de Lisboa\n",
    "\n",
    "Esse notebook busca coletar os dados dos periódicos digitalizados e disponíveis no site da Hemeroteca Digital de Lisboa. Os dados serão organizados em um *dataframe* e exportados para um arquivo csv.\n",
    "\n",
    "Os dados coletados são:\n",
    "\n",
    "- **Título**: Título do periódico\n",
    "- **Autoria**: Autoria do periódico\n",
    "- **Período**: Período disponível do periódico\n",
    "- **Link**: Link para o periódico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar bibliotecas\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir lista de letras que foram o índice\n",
    "letras = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J','L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U','V', 'X', 'Z']\n",
    "\n",
    "# definir url base\n",
    "url_base = 'https://hemerotecadigital.cm-lisboa.pt/Indice/Indice'\n",
    "\n",
    "# final da url\n",
    "url_final = '.htm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir lista de urls completa\n",
    "urls = [url_base + letra + url_final for letra in letras]\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para criar objeto soup\n",
    "def criar_soup(url):\n",
    "    html = requests.get(url)\n",
    "    soup = bs(html.content, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all a href that ends with .htm and start with ../Periodicos or ../OBRAS\n",
    "def encontrar_links(soup):\n",
    "    links = soup.find_all('a', href=True)\n",
    "    links = [link['href'] for link in links if link['href'].endswith('.htm') and (link['href'].startswith('../Periodicos') or link['href'].startswith('../OBRAS'))]\n",
    "    # replace ../ with https://hemerotecadigital.cm-lisboa.pt/\n",
    "    links = [link.replace('../', 'https://hemerotecadigital.cm-lisboa.pt/') for link in links]\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop com as urls\n",
    "links_geral = []\n",
    "for url in urls:\n",
    "    soup = criar_soup(url)\n",
    "    links = encontrar_links(soup)\n",
    "    links_geral.extend(links)\n",
    "print(len(links_geral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop nos links\n",
    "for link in links_geral:\n",
    "    soup = criar_soup(link)\n",
    "    print(soup.title.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
