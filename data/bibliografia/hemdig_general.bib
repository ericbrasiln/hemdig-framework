
@inproceedings{neudecker_making_2016,
	title = {Making {Europe}'s {Historical} {Newspapers} {Searchable}},
	isbn = {9781509017928 (ISBN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979556437&doi=10.1109%2fDAS.2016.83&partnerID=40&md5=8f07aa6473046bc026f95a822340502c},
	doi = {10.1109/DAS.2016.83},
	abstract = {This paper provides a rare glimpse into the overall approach for the refinement, i.e. the enrichment of scanned historical newspapers with text and layout recognition, in the Europeana Newspapers project. Within three years, the project processed more than 10 million pages of historical newspapers from 12 national and major libraries to produce the largest open access and fully searchable text collection of digital historical newspapers in Europe. In this, a wide variety of legal, logistical, technical and other challenges were encountered. After introducing the background issues in newspaper digitization in Europe, the paper discusses the technical aspects of refinement in greater detail. It explains what decisions were taken in the design of the large-scale processing workflow to address these challenges, what were the results produced and what were identified as best practices. © 2016 IEEE.},
	language = {English},
	urldate = {2016-04-11},
	booktitle = {Proc. - {IAPR} {Int}. {Workshop} {Doc}. {Anal}. {Syst}., {DAS}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Neudecker, C. and Antonacopoulos, A.},
	year = {2016},
	note = {Journal Abbreviation: Proc. - IAPR Int. Workshop Doc. Anal. Syst., DAS},
	keywords = {Best practices, Character recognition, digital libraries, Digital libraries, Digitisation, Electronic publishing, europeana, HEMDIG - PROJETOS SIMILARES, HEMDIG - SCOPUS, HEMDIG FRAMEWORK, historical newspapers, Historical newspapers, large-scale digitisation, Large-scale processing, layout analysis, Layout analysis, newspapers, Newsprint, OCR, OLR, Open Access, optical character recognition, Optical character recognition, SCOPUS, Technical aspects, Text collection},
	pages = {405--410},
	file = {neudecker_antonacopoulos_2016_making europe's historical newspapers searchable.pdf:/home/ebn/pCloudDrive/zot_library/IEEE/2016/neudecker_antonacopoulos_2016_making europe's historical newspapers searchable.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/L8533WTD/7490152.html:text/html},
}

@inproceedings{neudecker_large-scale_2014,
	title = {Large-scale refinement of digital historic newspapers with named entity recognition},
	booktitle = {Proc {IFLA} {Newspapers}/{GENLOC} {Pre}-{Conference} {Satellite} {Meeting}},
	author = {Neudecker, Clemens and Wilms, Lotte and Faber, Wille Jaan and van Veen, Theo},
	year = {2014},
	keywords = {europeana, HEMDIG - PROJETOS SIMILARES, HEMDIG FRAMEWORK, newspapers, OCR, OLR, ALTO XML, large-scale refinement, NER},
	file = {neudeckeret al_2014_large-scale refinement of digital historic newspapers with.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2014/neudeckeret al_2014_large-scale refinement of digital historic newspapers with.pdf:application/pdf},
}

@article{during_impresso_2021,
	title = {Impresso inspect and compare. {Visual} comparison of semantically enriched historical newspaper articles},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2078-2489},
	url = {https://www.mdpi.com/2078-2489/12/9/348},
	doi = {10.3390/info12090348},
	abstract = {The automated enrichment of mass-digitised document collections using techniques such as text mining is becoming increasingly popular. Enriched collections offer new opportunities for interface design to allow data-driven and visualisation-based search, exploration and interpretation. Most such interfaces integrate close and distant reading and represent semantic, spatial, social or temporal relations, but often lack contrastive views. Inspect and Compare (I\&C) contributes to the current state of the art in interface design for historical newspapers with highly versatile side-by-side comparisons of query results and curated article sets based on metadata and semantic enrichments. I\&C takes search queries and pre-curated article sets as inputs and allows comparisons based on the distributions of newspaper titles, publication dates and automatically generated enrichments, such as language, article types, topics and named entities. Contrastive views of such data reveal patterns, help humanities scholars to improve search strategies and to facilitate a critical assessment of the overall data quality. I\&C is part of the impresso interface for the exploration of digitised and semantically enriched historical newspapers. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	language = {en},
	number = {9},
	journal = {Information},
	author = {Düring, M. and Kalyakin, R. and Bunout, E. and Guido, D.},
	year = {2021},
	note = {Publisher: MDPI},
	keywords = {Automatically generated, comparison, Comparison, Critical assessment, data criticism, Data criticism, digital history, Digital history, digital humanities, Digital humanities, diverging bar charts, Diverging bar charts, Document collection, GUI, HEMDIG - PROJETOS SIMILARES, HEMDIG - SCOPUS, HEMDIG FRAMEWORK, historical newspapers, Historical newspapers, impresso project, Interface states, metadata, Metadata, Natural language processing systems, newspapers, Newsprint, SCOPUS, search, Search, Search strategies, semantic enrichment, Semantic enrichment, Semantics, small multiples, Small multiples, Temporal relation, Text mining, user interface, User interface, Visual comparison},
	pages = {348},
	file = {düring_et_al_2021_impresso_inspect_and_compare.pdf:/home/ebn/pCloudDrive/zot_library/Information/2021/düring_et_al_2021_impresso_inspect_and_compare.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/5DHY9STI/348.html:text/html},
}

@inproceedings{liebl_historical_2020,
	address = {Amsterdam},
	title = {From historical newspapers to machine-readable data: {The} origami {OCR} pipeline},
	volume = {2723},
	isbn = {16130073 (ISSN)},
	url = {http://ceur-ws.org/Vol-2723/long20.pdf},
	abstract = {While historical newspapers recently have gained a lot of attention in the digital humanities, transforming them into machine-readable data by means of OCR poses some major challenges. In order to address these challenges, we have developed an end-to-end OCR pipeline named Origami. This pipeline is part of a current project on the digitization and quantitative analysis of the German newspaper "Berliner Börsen-Zeitung"(BBZ), from 1872 to 1931. The Origami pipeline reuses existing open source OCR components and on top offers a new configurable architecture for layout detection, a simple table recognition, a two-stage X-Y cut for reading order detection, and a new robust implementation for document dewarping. In this paper we describe the different stages of the workflow and discuss how they meet the above-mentioned challenges posed by historical newspapers. © 2020 Copyright for this paper by its authors.},
	language = {en},
	urldate = {2020-11-18},
	booktitle = {{CEUR} {Workshop} {Proc}.},
	publisher = {CEUR-WS},
	author = {Liebl, B. and Burghardt, M.},
	editor = {{Karsdorp F.} and {McGillivray B.} and {Nerghes A.} and {Wevers M.}},
	year = {2020},
	note = {Journal Abbreviation: CEUR Workshop Proc.},
	keywords = {Configurable architectures, Current projects, Deep neural networks, Different stages, Digital humanities, digital tool, End-to-end OCR, German newspapers, HEMDIG - SCOPUS, HEMDIG FRAMEWORK, Historical newspapers, Humanities computing, Layout detection, Metadata, newspapers, Newsprint, OCR, OLR, Order detections, origami ocr pipeline, Pipelines, Readable data, SCOPUS},
	pages = {351--373},
	file = {liebl_burghardt_from_historical_newspapers_to_machine-readable_data.pdf:/home/ebn/pCloudDrive/zot_library/undefined/undefined/liebl_burghardt_from_historical_newspapers_to_machine-readable_data.pdf:application/pdf},
}

@inproceedings{pletschacher_europeana_2015,
	title = {Europeana newspapers {OCR} workflow evaluation},
	isbn = {9781450336024 (ISBN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014883617&doi=10.1145%2f2809544.2809554&partnerID=40&md5=9106dbb1686730d5f3b8f2b30d737722},
	doi = {10.1145/2809544.2809554},
	abstract = {This paper summarises the final performance evaluation results of the OCR workflow which was employed for large-scale production in the Europeana Newspapers project. It gives a detailed overview of how the involved software performed on a representative dataset of historical newspaper pages (for which ground truth was created) with regard to general text accuracy as well as layout-related factors which have an impact on how the material can be used in specific use scenarios. Specific types of errors are examined and evaluated in order to identify possible improvements related to the employed document image analysis and recognition methods. Moreover, alternatives to the standard production workflow are assessed to determine future directions and give advice on best practice related to OCR projects. © 2015 ACM.},
	language = {English},
	urldate = {2015-08-22},
	booktitle = {Proceedings of the 3rd international workshop on historical document imaging and processing},
	publisher = {Association for Computing Machinery},
	author = {Pletschacher, S. and Clausner, C. and Antonacopoulos, A.},
	collaborator = {{FamilySearch}},
	year = {2015},
	note = {Journal Abbreviation: ACM Int. Conf. Proc. Ser.},
	keywords = {Document image analysis and recognition, europeana, evaluation, Evaluation results, HEMDIG - PROJETOS SIMILARES, HEMDIG - SCOPUS, HEMDIG FRAMEWORK, Historical documents, Historical newspapers, History, Image processing, Large scale productions, newspapers, Newspapers, Newsprint, OCR, Optical character recognition, Performance evaluation, Production workflows, SCOPUS, workflow},
	pages = {39--46},
	file = {pletschacheret al_2015_europeana newspapers ocr workflow evaluation.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2015/pletschacheret al_2015_europeana newspapers ocr workflow evaluation.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/8BZCEDCV/2809544.html:text/html},
}

@article{hechl_digital_2021,
	title = {Digital interfaces of historical newspapers: opportunities, restrictions and recommendations},
	volume = {HistoInformatics},
	issn = {2416-5999},
	shorttitle = {Digital interfaces of historical newspapers},
	url = {https://jdmdh.episciences.org/7069/pdf},
	doi = {10.46298/jdmdh.6121},
	abstract = {Many libraries offer free access to digitised historical newspapers via user interfaces. After an initial period of search and filter options as the only features, the availability of more advanced tools and the desire for more options among users has ushered in a period of interface development. However, this raises a number of open questions and challenges. For example, how can we provide interfaces for different user groups? What tools should be available on interfaces and how can we avoid too much complexity? What tools are helpful and how can we improve usability? This paper will not provide definite answers to these questions, but it gives an insight into the difficulties, challenges and risks of using interfaces to investigate historical newspapers. More importantly, it provides ideas and recommendations for the improvement of user interfaces and digital tools.},
	language = {en},
	number = {jdmdh:6121},
	urldate = {2022-03-19},
	journal = {Journal of Data Mining \& Digital Humanities},
	author = {Hechl, Stefan and Langlais, Pierre-Carl and Marjanen, Jani and Oberbichler, Sarah and Pfanzelter, Eva},
	year = {2021},
	note = {Publisher: Episciences.org},
	keywords = {HEMDIG FRAMEWORK, newspapers, GUI, topic modeling},
	file = {hechlet al_2021_digital interfaces of historical newspapers.pdf:/home/ebn/pCloudDrive/zot_library/Journal of Data Mining & Digital Humanities/2021/hechlet al_2021_digital interfaces of historical newspapers.pdf:application/pdf;pfanzelter_et_al_2020_digital_interfaces_of_historical_newspapers.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2020/pfanzelter_et_al_2020_digital_interfaces_of_historical_newspapers.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/Z4WVIYLL/7069.html:text/html},
}

@article{kaplan_combining_2021,
	title = {Combining visual and textual features for semantic segmentation of historical newspapers},
	volume = {HistoInformatics},
	url = {https://jdmdh.episciences.org/7097/pdf},
	doi = {10.46298/jdmdh.6107},
	abstract = {The massive amounts of digitized historical documents acquired over the last decades naturally lend themselves to automatic processing and exploration. Research work seeking to automatically process facsimiles and extract information thereby are multiplying with, as a first essential step, document layout analysis. If the identification and categorization of segments of interest in document images have seen significant progress over the last years thanks to deep learning techniques, many challenges remain with, among others, the use of finer-grained segmentation typologies and the consideration of complex, heterogeneous documents such as historical newspapers. Besides, most approaches consider visual features only, ignoring textual signal. In this context, we introduce a multimodal approach for the semantic segmentation of historical newspapers that combines visual and textual features. Based on a series of experiments on diachronic Swiss and Luxembourgish newspapers, we investigate, among others, the predictive power of visual and textual features and their capacity to generalize across time and sources. Results show consistent improvement of multimodal models in comparison to a strong visual baseline, as well as better robustness to high material variance.},
	language = {en},
	urldate = {2022-03-19},
	journal = {Journal of Data Mining \& Digital Humanities},
	author = {Kaplan, Frédéric and Oliveira, Sofia Ares and Clematide, Simon and Ehrmann, Maud and Barman, Raphaël},
	year = {2021},
	note = {Publisher: Episciences.org},
	keywords = {HEMDIG FRAMEWORK, newspapers, OCR, deep learning, image segmentation, semantic segmentation},
	file = {kaplanet al_2021_combining visual and textual features for semantic2.pdf:/home/ebn/pCloudDrive/zot_library/Journal of Data Mining & Digital Humanities/2021/kaplanet al_2021_combining visual and textual features for semantic2.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/GKPJNTIU/7097.html:text/html},
}

@article{moreux_innovative_2017,
	title = {Innovative {Approaches} of {Historical} {Newspapers}: {Data} {Mining}, {Data} {Visualization}, {Semantic} {Enrichment}},
	shorttitle = {Innovative {Approaches} of {Historical} {Newspapers}},
	author = {Moreux, Jean-Philippe},
	year = {2017},
	keywords = {europeana, HEMDIG - PROJETOS SIMILARES, HEMDIG FRAMEWORK, newspapers, OLR, ALTO XML, NER, data visualisation, data mining},
	file = {moreux_2017_innovative approaches of historical newspapers.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2017/moreux_2017_innovative approaches of historical newspapers.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/V4CDUHUG/2076.html:text/html},
}

@incollection{hamdi_multilingual_2021,
	address = {New York, NY, USA},
	title = {A {Multilingual} {Dataset} for {Named} {Entity} {Recognition}, {Entity} {Linking} and {Stance} {Detection} in {Historical} {Newspapers}},
	isbn = {978-1-4503-8037-9},
	url = {https://doi.org/10.1145/3404835.3463255},
	abstract = {Named entity processing over historical texts is more and more being used due to the massive documents and archives being stored in digital libraries. However, due to the poor annotated resources of historical nature, information extraction performances fall behind those on contemporary texts. In this paper, we introduce the development of the NewsEye resource, a multilingual dataset for named entity recognition and linking enriched with stances towards named entities. The dataset is comprised of diachronic historical newspaper material published between 1850 and 1950 in French, German, Finnish, and Swedish. Such historical resource is essential in the context of developing and evaluating named entity processing systems. It evenly allows enhancing the performances of existing approaches on historical documents which enables adequate and efficient semantic indexing of historical documents on digital cultural heritage collections.},
	urldate = {2022-03-18},
	booktitle = {Proceedings of the 44th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Hamdi, Ahmed and Linhares Pontes, Elvys and Boros, Emanuela and Nguyen, Thi Tuyet Hai and Hackl, Günter and Moreno, Jose G. and Doucet, Antoine},
	month = jul,
	year = {2021},
	keywords = {named entity recognition, HEMDIG - PROJETOS SIMILARES, HEMDIG FRAMEWORK, newspapers, NER, datasets, diachronic historical newspapers, entity linking, multilingual, newseye, stance detection},
	pages = {2328--2334},
	file = {hamdiet_al_2021_a_multilingual_dataset_for_named_entity_recognition,_entity.pdf:/home/ebn/pCloudDrive/zot_library/Association for Computing Machinery/2021/hamdiet_al_2021_a_multilingual_dataset_for_named_entity_recognition,_entity.pdf:application/pdf},
}

@article{ehrmann_language_2020,
	title = {Language resources for historical newspapers: the impresso collection},
	shorttitle = {Language resources for historical newspapers},
	author = {Ehrmann, Maud and Romanello, Matteo and Clematide, Simon and Ströbel, Phillip and Barman, Raphaël},
	year = {2020},
	note = {Publisher: European Language Resources Association (ELRA)},
	keywords = {HEMDIG - PROJETOS SIMILARES, HEMDIG FRAMEWORK, impresso project, multilingual, NER, newspapers, OCR, semantic annotation, topic modeling},
	file = {ehrmannet al_2020_language resources for historical newspapers.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2020/ehrmannet al_2020_language resources for historical newspapers.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/5PPQRQ5U/191270.html:text/html},
}

@inproceedings{pekarek_europeana_2012,
	title = {The europeana newspapers–a gateway to european newspapers online},
	booktitle = {Euro-{Mediterranean} {Conference}},
	publisher = {Springer},
	author = {Pekárek, Aleš and Willems, Marieke},
	year = {2012},
	keywords = {europeana, HEMDIG - PROJETOS SIMILARES, HEMDIG FRAMEWORK, newspapers, OCR, OLR, NER},
	pages = {654--659},
	file = {pekárek_willems_2012_the europeana newspapers–a gateway to european newspapers.pdf:/home/ebn/pCloudDrive/zot_library/Springer/2012/pekárek_willems_2012_the europeana newspapers–a gateway to european newspapers.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/69LAMYW2/978-3-642-34234-9_68.html:text/html},
}

@inproceedings{moreux_data_2016,
	title = {Data mining historical newspaper metadata},
	booktitle = {Proceedings of the {IFLA} {International} {News} {Media} {Conference} (04 2016). https://www. researchgate. net/publication/291833336\_Data\_Mining\_Historical\_Newspaper\_Metadata},
	author = {Moreux, Jean-Philippe},
	year = {2016},
	keywords = {europeana, HEMDIG - PROJETOS SIMILARES, HEMDIG FRAMEWORK, newspapers, OCR, OLR, ALTO XML, data visualization, data mining},
	file = {moreux_2016_data mining historical newspaper metadata.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2016/moreux_2016_data mining historical newspaper metadata.pdf:application/pdf},
}

@article{reilly_challenge_2013,
	title = {The challenge of making digitised {European} newspaper content available online},
	author = {Reilly, Susan},
	year = {2013},
	keywords = {europeana, HEMDIG - PROJETOS SIMILARES, HEMDIG FRAMEWORK, newspapers},
	file = {reilly_2013_the challenge of making digitised european newspaper.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2013/reilly_2013_the challenge of making digitised european newspaper.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/9SEU27QD/255.html:text/html},
}

@techreport{ehrmann_historical_2020,
	title = {Historical {Newspaper} {Content} {Mining}: {Revisiting} the impresso {Project}'s {Challenges} in {Text} and {Image} {Processing}, {Design} and {Historical} {Scholarship}},
	shorttitle = {Historical {Newspaper} {Content} {Mining}},
	institution = {ADHO},
	author = {Ehrmann, Maud and Bunout, Estelle and Clematide, Simon and Düring, Marten and Fickers, Andreas and Guido, Daniele and Kalyakin, Roman and Kaplan, Frédéric and Romanello, Matteo and Schroeder, Paul},
	year = {2020},
	keywords = {HEMDIG - PROJETOS SIMILARES, HEMDIG FRAMEWORK, newspapers, impresso project, image processing, text processing},
	file = {ehrmannet al_2020_historical newspaper content mining.pdf:/home/ebn/pCloudDrive/zot_library/ADHO/2020/ehrmannet al_2020_historical newspaper content mining.pdf:application/pdf},
}

@article{oberbichler_integrated_2022,
	title = {Integrated interdisciplinary workflows for research on historical newspapers: {Perspectives} from humanities scholars, computer scientists, and librarians},
	volume = {73},
	issn = {2330-1643},
	shorttitle = {Integrated interdisciplinary workflows for research on historical newspapers},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.24565},
	doi = {10.1002/asi.24565},
	abstract = {This article considers the interdisciplinary opportunities and challenges of working with digital cultural heritage, such as digitized historical newspapers, and proposes an integrated digital hermeneutics workflow to combine purely disciplinary research approaches from computer science, humanities, and library work. Common interests and motivations of the above-mentioned disciplines have resulted in interdisciplinary projects and collaborations such as the NewsEye project, which is working on novel solutions on how digital heritage data is (re)searched, accessed, used, and analyzed. We argue that collaborations of different disciplines can benefit from a good understanding of the workflows and traditions of each of the disciplines involved but must find integrated approaches to successfully exploit the full potential of digitized sources. The paper is furthermore providing an insight into digital tools, methods, and hermeneutics in action, showing that integrated interdisciplinary research needs to build something in between the disciplines while respecting and understanding each other's expertise and expectations.},
	language = {en},
	number = {2},
	urldate = {2022-03-19},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Oberbichler, Sarah and Boroş, Emanuela and Doucet, Antoine and Marjanen, Jani and Pfanzelter, Eva and Rautiainen, Juha and Toivonen, Hannu and Tolonen, Mikko},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.24565},
	keywords = {HEMDIG - PROJETOS SIMILARES, HEMDIG FRAMEWORK, newspapers, workflow, Interdisciplinary collaborations, newseye},
	pages = {225--239},
	file = {oberbichleret al_2022_integrated interdisciplinary workflows for research on.pdf:/home/ebn/pCloudDrive/zot_library/Journal of the Association for Information Science and Technology/2022/oberbichleret al_2022_integrated interdisciplinary workflows for research on.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/8N2I3GKD/asi.html:text/html},
}

@misc{brasil_analise_pyhdb_2022,
	title = {analise\_pyHDB},
	copyright = {MIT},
	url = {https://github.com/ericbrasiln/analise_pyHDB},
	abstract = {Scripts para geração de gráficos a partir do dataset criado com a ferramenta pyHDB},
	urldate = {2022-10-28},
	author = {Brasil, Eric},
	month = feb,
	year = {2022},
	note = {original-date: 2021-11-14T02:39:31Z},
	keywords = {HEMDIG FRAMEWORK},
}

@misc{noauthor_interface_2022,
	title = {Interface gráfica do utilizador},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://pt.wikipedia.org/w/index.php?title=Interface_gr%C3%A1fica_do_utilizador&oldid=63533578},
	abstract = {Em informática, interface gráfica do utilizador (português europeu) ou usuário (português brasileiro) (abreviadamente, o acrônimo GUI, do inglês Graphical User Interface) é um tipo de interface do utilizador que permite a interação com dispositivos digitais por meio de elementos gráficos como ícones e outros indicadores visuais, em contraste a interface de linha de comando. Foi criada pela Xerox mas somente se tornou um produto com a Apple.A interação é feita geralmente com um mouse ou um teclado, com os quais o usuário é capaz de selecionar símbolos e manipulá-los de forma a obter algum resultado prático. Esses símbolos são designados de widgets e são agrupados em kits.
Ambiente gráfico é um software feito para facilitar e tornar prática a utilização do computador por meio de representações visuais do sistema operacional.
Para Windows temos apenas o ambiente gráfico padrão, nas versões Windows Vista e Windows 7 temos a chamada Windows Aero. Para GNU/Linux temos vários ambientes gráficos, entre eles, o KDE, Gnome, BlackBox, Xfce, LXDE, etc.. Há também a opção de não precisar usar ambientes gráficos. Para prover a funcionalidade do ambiente gráfico existem programas como X.org, XFree86.},
	language = {pt},
	urldate = {2022-10-25},
	journal = {Wikipédia, a enciclopédia livre},
	month = may,
	year = {2022},
	note = {Page Version ID: 63533578},
	keywords = {GUI, HEMDIG FRAMEWORK},
	file = {Snapshot:/home/ebn/Zotero/storage/E832I2L4/Interface_gráfica_do_utilizador.html:text/html},
}

@misc{noauthor_graphical_2022,
	title = {Graphical user interface},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Graphical_user_interface&oldid=1116620039},
	abstract = {The GUI ( JEE-yoo-EYE or  GOO-ee), graphical user interface, is a form of user interface that allows users to interact with electronic devices through graphical icons and audio indicator such as primary notation, instead of text-based UIs, typed command labels or text navigation. GUIs were introduced in reaction to the perceived steep learning curve of CLIs (command-line interfaces), which require commands to be typed on a computer keyboard.
The actions in a GUI are usually performed through direct manipulation of the graphical elements. Beyond computers, GUIs are used in many handheld mobile devices such as MP3 players, portable media players, gaming devices, smartphones and smaller household, office and industrial controls. The term GUI tends not to be applied to other lower-display resolution types of interfaces, such as video games (where HUD (head-up display) is preferred), or not including flat screens like volumetric displays because the term is restricted to the scope of 2D display screens able to describe generic information, in the tradition of the computer science research at the Xerox Palo Alto Research Center.},
	language = {en},
	urldate = {2022-10-25},
	journal = {Wikipedia},
	month = oct,
	year = {2022},
	note = {Page Version ID: 1116620039},
	keywords = {GUI, HEMDIG FRAMEWORK},
	file = {Snapshot:/home/ebn/Zotero/storage/APEEIPMJ/Graphical_user_interface.html:text/html},
}

@article{maia_processing_2020,
	title = {Processing topical queries on images of historical newspaper pages},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2002.08500},
	doi = {10.48550/ARXIV.2002.08500},
	abstract = {Historical newspapers are a source of research for the human and social sciences. However, these image collections are difficult to read by machine due to the low quality of the print, the lack of standardization of the pages in addition to the low quality photograph of some files. This paper presents the processing model of a topic navigation system in historical newspaper page images. The general procedure consists of four modules which are: segmentation of text sub-images and text extraction, preprocessing and representation, induced topic extraction and representation, and document viewing and retrieval interface. The algorithmic and technological approaches of each module are described and the initial test results about a collection covering a range of 28 years are presented.},
	urldate = {2022-08-12},
	author = {Maia, José E. B. and Sá, Gildácio J. de A.},
	year = {2020},
	note = {Publisher: arXiv
Version Number: 1},
	keywords = {HEMDIG FRAMEWORK, newspapers, NER, image processing, NLP},
	file = {maia_sá_2020_processing topical queries on images of historical.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2020/maia_sá_2020_processing topical queries on images of historical.pdf:application/pdf},
}

@article{azevedo_hemeroteca_2019,
	title = {A {Hemeroteca} {Digital} {Brasileira}: {Fontes} {E} {Possibilidades} {Para} a {Pesquisa} {Em} {História} {Da} {Educação}},
	volume = {2},
	copyright = {Copyright (c)},
	issn = {2595-4881},
	shorttitle = {A {Hemeroteca} {Digital} {Brasileira}},
	url = {https://www.revistas.uneb.br/index.php/cenaseducacionais/article/view/7361},
	abstract = {Resumo
					A Hemeroteca Digital Brasileira vinculada à Fundação Biblioteca Nacional disponibiliza aos pesquisadores a consulta ao seu acervo digital de periódicos, jornais, revistas e outros documentos, de forma livre e gratuita. Este artigo objetiva apresentar e discutir a hemeroteca digital como fonte para a História da Educação potiguar, tendo como foco a investigação acerca do intelectual norte-rio-grandense Nestor dos Santos Lima. O artigo foi construído de modo a descrever o percurso de pesquisa realizado no portal. O recorte espaço-temporal investigado compreendeu os documentos não apenas no Rio Grande do Norte, mas em outros Estados no período de 1900 a 1930. Entre os jornais disponibilizados na Hemeroteca e que se constituíram enquanto resultados da pesquisa apontamos, por exemplo, “O Paiz” e o “Jornal do Comércio” do Rio de Janeiro, o “Correio Paulistano” de São Paulo e o “Diário de Pernambuco”. Para a realização da pesquisa, nos pautamos principalmente em Le Goff (1990), Certeau (1982), Zicman (1985) e Luca (2008). Ressaltamos a potencialidade da imprensa enquanto fonte para História da Educação e a necessidade da crítica ao documento que, muitas vezes se revela parcial e subjetivo, permeado por intencionalidades. Destacamos, sobretudo, a relevância da Hemeroteca Digital enquanto repositório de fontes para a História da Educação. Como possibilidades advindas da pesquisa na hemeroteca digital sobre Nestor Lima, apontamos os indícios da relação que o intelectual constrói com a imprensa, as sociabilidades apresentadas, além das marcas de sua atuação no campo educacional no Estado e sua repercussão nacional durante o período da Primeira República.},
	language = {pt},
	urldate = {2022-05-17},
	journal = {Cenas Educacionais},
	author = {Azevedo, Laís Paula de Medeiros Campos and Pessoa, Lígia Silvia and Neta, Olívia Morais de Medeiros},
	year = {2019},
	keywords = {HDB, HEMDIG FRAMEWORK, newspapers, OCR},
	pages = {39--55},
	file = {azevedoet al_2019_a hemeroteca digital brasileira.pdf:/home/ebn/pCloudDrive/zot_library/Cenas Educacionais/2019/azevedoet al_2019_a hemeroteca digital brasileira.pdf:application/pdf},
}

@article{zhu_pdfdataextractor_2022,
	title = {{PDFDataExtractor}: {A} {Tool} for {Reading} {Scientific} {Text} and {Interpreting} {Metadata} from the {Typeset} {Literature} in the {Portable} {Document} {Format}},
	volume = {62},
	issn = {1549-9596},
	shorttitle = {{PDFDataExtractor}},
	url = {https://doi.org/10.1021/acs.jcim.1c01198},
	doi = {10.1021/acs.jcim.1c01198},
	abstract = {The layout of portable document format (PDF) files is constant to any screen, and the metadata therein are latent, compared to mark-up languages such as HTML and XML. No semantic tags are usually provided, and a PDF file is not designed to be edited or its data interpreted by software. However, data held in PDF files need to be extracted in order to comply with open-source data requirements that are now government-regulated. In the chemical domain, related chemical and property data also need to be found, and their correlations need to be exploited to enable data science in areas such as data-driven materials discovery. Such relationships may be realized using text-mining software such as the “chemistry-aware” natural-language-processing tool, ChemDataExtractor; however, this tool has limited data-extraction capabilities from PDF files. This study presents the PDFDataExtractor tool, which can act as a plug-in to ChemDataExtractor. It outperforms other PDF-extraction tools for the chemical literature by coupling its functionalities to the chemical-named entity-recognition capabilities of ChemDataExtractor. The intrinsic PDF-reading abilities of ChemDataExtractor are much improved. The system features a template-based architecture. This enables semantic information to be extracted from the PDF files of scientific articles in order to reconstruct the logical structure of articles. While other existing PDF-extracting tools focus on quantity mining, this template-based system is more focused on quality mining on different layouts. PDFDataExtractor outputs information in JSON and plain text, including the metadata of a PDF file, such as paper title, authors, affiliation, email, abstract, keywords, journal, year, document object identifier (DOI), reference, and issue number. With a self-created evaluation article set, PDFDataExtractor achieved promising precision for all key assessed metadata areas of the document text.},
	number = {7},
	urldate = {2022-05-05},
	journal = {Journal of Chemical Information and Modeling},
	author = {Zhu, Miao and Cole, Jacqueline M.},
	month = apr,
	year = {2022},
	note = {Publisher: American Chemical Society},
	keywords = {digital tool, HEMDIG FRAMEWORK, information retrieval, PDF, PDFDataExtractor},
	pages = {1633--1643},
	file = {ACS Full Text Snapshot:/home/ebn/Zotero/storage/YH3ZS6ET/acs.jcim.html:text/html;zhu_cole_2022_pdfdataextractor.pdf:/home/ebn/pCloudDrive/zot_library/Journal of Chemical Information and Modeling/2022/zhu_cole_2022_pdfdataextractor.pdf:application/pdf},
}

@article{blaney_culture_2016,
	title = {A {Culture} of non-citation: {Assessing} the digital impact of {British} {History} {Online} and the {Early} {English} {Books} {Online} {Text} {Creation} {Partnership}},
	volume = {011},
	issn = {1938-4122},
	shorttitle = {A {Culture} of non-citation},
	number = {1},
	journal = {Digital Humanities Quarterly},
	author = {Blaney, Jonathan and Siefring, Judith},
	month = dec,
	year = {2016},
	keywords = {citation patterns, digital libraries, HEMDIG FRAMEWORK},
	file = {blaney_siefring_2016_a culture of non-citation.pdf:/home/ebn/pCloudDrive/zot_library/Digital Humanities Quarterly/2016/blaney_siefring_2016_a culture of non-citation.pdf:application/pdf;DHQ\: Digital Humanities Quarterly\: A Culture of non-citation\: Assessing the digital impact of British History Online and the Early English Books Online Text Creation Partnership:/home/ebn/Zotero/storage/WRYJU5I6/000282.html:text/html},
}

@article{milligan_illusionary_2013,
	title = {Illusionary {Order}: {Online} {Databases}, {Optical} {Character} {Recognition}, and {Canadian} {History}, 1997–2010},
	volume = {94},
	issn = {1710-1093},
	shorttitle = {Illusionary {Order}},
	url = {https://muse.jhu.edu/article/527016},
	abstract = {It all seems so orderly and comprehensive. Instead of firing up the micro-film reader to navigate the Globe and Mail or the Toronto Star, one needs only to log into online newspaper databases. A keyword search, for a particular event, person, or cultural phenomenon, brings up a list of research findings. Previously impossible research projects can now be attempted. This process has fundamentally reshaped Canadian historical scholarship. We can see this in Canadian history dissertations. In 1998, a year with 67 dissertations, the Toronto Star was cited 74 times. However it was cited 753 times in 2010, a year with 69 dissertations. Similar data appears in the Canadian Historical Review (CHR), a prestigious peer-reviewed journal. Databases are skewing our research. We are witnessing the application of commercial Optical Character Recognition (OCR) technology – originally and primarily designed for the efficient digitization of large reams of corporate and legal documents, conventionally formatted – to historical sources. The results are, unsurprisingly, a mixed bag. In this article, I make two arguments. Firstly, online historical databases have profoundly shaped Canadian historiography. In a shift that is rarely – if ever – made explicit, Canadian historians have profoundly reacted to the availability of online databases. Secondly, historians need to understand how OCR works, in order to bring a level of methodological rigor to their work that use these sources.
	, 
	  Ça paraît si bien classé, si complet. Au lieu d’allumer le lecteur de microfilms pour sillonner le Globe and Mail ou le Toronto Star, on a seulement besoin de se connecter aux bases de données en ligne des journaux. Pour tout événement, toute personne ou tout phénomène culturel, une recherche par mot clé génère une liste de résultats. Des projets de recherche autrefois impossibles sont maintenant lancés. La recherche de pointe en histoire au Canada a été radicalement transformée, et les thèses en histoire canadienne nous le prouvent. Les 67 thèses déposées en 1998 ont cité le Toronto Star 74 fois; les 69 thèses déposées en 2010 l’ont plutôt cité 753 fois. Des données semblables s’observent dans la Canadian Historical Review (CHR), une prestigieuse revue périodique à comité de lecture. Les bases de données biaisent la recherche. La technologie commerciale de reconnaissance de caractères, initialement et principalement conçue pour numériser efficacement d’énormes quantités de documents d’entreprise ou juridiques à la mise en forme conventionnelle, s’applique désormais aux sources en histoire avec, sans surprise, des résultats qui laissent parfois à désirer. Je défendrai deux idées dans cet article. Premièrement, les bases de données historiques en ligne ont profondément marqué l’historiographie canadienne. On admet peu, si tant est qu’on le fasse, à quel point les historiens canadiens ont investi les bases de données en ligne. Deuxièmement, les historiens doivent comprendre comment fonctionne la reconnaissance de caractères pour garantir la rigueur méthodologique de leurs travaux fondés sur ces sources.},
	number = {4},
	urldate = {2022-04-27},
	journal = {The Canadian Historical Review},
	author = {Milligan, Ian},
	year = {2013},
	note = {Publisher: University of Toronto Press},
	keywords = {databases, HEMDIG FRAMEWORK, newspapers, OCR},
	pages = {540--569},
	file = {milligan_2013_illusionary order.pdf:/home/ebn/pCloudDrive/zot_library/The Canadian Historical Review/2013/milligan_2013_illusionary order.pdf:application/pdf},
}

@article{kan_computer-assisted_1977,
	title = {Computer-assisted layout of newspapers},
	author = {Kan, Hsin-Kuo and Reintjes, J. Francis and Knudson, Donald R.},
	year = {1977},
	note = {Publisher: Massachusetts Institute of Technology, Dept. of Electrical Engineering and …},
	keywords = {HEMDIG FRAMEWORK, newspapers, newspaper layout},
	file = {kanet al_1977_computer-assisted layout of newspapers.pdf:/home/ebn/pCloudDrive/zot_library/undefined/1977/kanet al_1977_computer-assisted layout of newspapers.pdf:application/pdf},
}

@inproceedings{shen_layoutparser_2021,
	title = {{LayoutParser}: {A} unified toolkit for deep learning based document image analysis},
	shorttitle = {{LayoutParser}},
	booktitle = {International {Conference} on {Document} {Analysis} and {Recognition}},
	publisher = {Springer},
	author = {Shen, Zejiang and Zhang, Ruochen and Dell, Melissa and Lee, Benjamin Charles Germain and Carlson, Jacob and Li, Weining},
	year = {2021},
	keywords = {deep learning, digital tool, HEMDIG FRAMEWORK, image analysis, layout analysis, OCR},
	pages = {131--146},
	file = {shenet al_2021_layoutparser.pdf:/home/ebn/pCloudDrive/zot_library/Springer/2021/shenet al_2021_layoutparser.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/MHCVR4L3/978-3-030-86549-8_9.html:text/html},
}

@inproceedings{hebert_automatic_2014,
	title = {Automatic article extraction in old newspapers digitized collections},
	booktitle = {Proceedings of the {First} {International} {Conference} on {Digital} {Access} to {Textual} {Cultural} {Heritage}},
	author = {Hebert, David and Palfray, Thomas and Nicolas, Stephane and Tranouez, Pierrick and Paquet, Thierry},
	year = {2014},
	keywords = {HEMDIG FRAMEWORK, layout analysis, newspapers, OLR, ALTO XML, article segmentation, image labelling},
	pages = {3--8},
	file = {hebertet al_2014_automatic article extraction in old newspapers digitized.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2014/hebertet al_2014_automatic article extraction in old newspapers digitized.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/8WD6E3GW/2595188.html:text/html},
}

@article{martinek_building_2020,
	title = {Building an efficient {OCR} system for historical documents with little training data},
	volume = {32},
	issn = {1433-3058},
	url = {https://doi.org/10.1007/s00521-020-04910-x},
	doi = {10.1007/s00521-020-04910-x},
	abstract = {As the number of digitized historical documents has increased rapidly during the last a few decades, it is necessary to provide efficient methods of information retrieval and knowledge extraction to make the data accessible. Such methods are dependent on optical character recognition (OCR) which converts the document images into textual representations. Nowadays, OCR methods are often not adapted to the historical domain; moreover, they usually need a significant amount of annotated documents. Therefore, this paper introduces a set of methods that allows performing an OCR on historical document images using only a small amount of real, manually annotated training data. The presented complete OCR system includes two main tasks: page layout analysis including text block and line segmentation and OCR. Our segmentation methods are based on fully convolutional networks, and the OCR approach utilizes recurrent neural networks. Both approaches are state of the art in the relevant fields. We have created a novel real dataset for OCR from Porta fontium portal. This corpus is freely available for research, and all proposed methods are evaluated on these data. We show that both the segmentation and OCR tasks are feasible with only a few annotated real data samples. The experiments aim at determining the best way how to achieve good performance with the given small set of data. We also demonstrate that obtained scores are comparable or even better than the scores of several state-of-the-art systems. To sum up, this paper shows a way how to create an efficient OCR system for historical documents with a need for only a little annotated training data.},
	language = {en},
	number = {23},
	urldate = {2021-11-24},
	journal = {Neural Computing and Applications},
	author = {Martínek, Jiří and Lenc, Ladislav and Král, Pavel},
	month = dec,
	year = {2020},
	keywords = {HEMDIG FRAMEWORK, OCR, neural networks, historical documents, documentos históricos, porta fontium},
	pages = {17209--17227},
	file = {martínek_et_al_2020_building_an_efficient_ocr_system_for_historical_documents_with_little_training.pdf:/home/ebn/pCloudDrive/zot_library/Neural Computing and Applications/2020/martínek_et_al_2020_building_an_efficient_ocr_system_for_historical_documents_with_little_training.pdf:application/pdf;martínek_et_al_2020_building_an_efficient_ocr_system_for_historical_documents_with_little_training.pdf:/home/ebn/pCloudDrive/zot_library/Neural Computing and Applications/2020/martínek_et_al_2020_building_an_efficient_ocr_system_for_historical_documents_with_little_training2.pdf:application/pdf},
}

@inproceedings{wiedemann_page_2018,
	address = {Miyazaki, Japan},
	title = {Page {Stream} {Segmentation} with {Convolutional} {Neural} {Nets} {Combining} {Textual} and {Visual} {Features}},
	url = {https://aclanthology.org/L18-1581},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2018)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Wiedemann, Gregor and Heyer, Gerhard},
	month = may,
	year = {2018},
	keywords = {HEMDIG FRAMEWORK, image labelling, neural networks, page segmentation},
	file = {wiedemann_heyer_2018_page stream segmentation with convolutional neural nets.pdf:/home/ebn/pCloudDrive/zot_library/European Language Resources Association (ELRA)/2018/wiedemann_heyer_2018_page stream segmentation with convolutional neural nets.pdf:application/pdf},
}

@inproceedings{pirovani_portuguese_2018,
	address = {Miyazaki, Japan},
	title = {Portuguese {Named} {Entity} {Recognition} using {Conditional} {Random} {Fields} and {Local} {Grammars}},
	url = {https://aclanthology.org/L18-1705},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2018)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Pirovani, Juliana and Oliveira, Elias},
	year = {2018},
	keywords = {HEMDIG FRAMEWORK, NER, digital tool, harem, portuguese},
	file = {pirovani_oliveira_2018_portuguese named entity recognition using conditional.pdf:/home/ebn/pCloudDrive/zot_library/European Language Resources Association (ELRA)/2018/pirovani_oliveira_2018_portuguese named entity recognition using conditional.pdf:application/pdf},
}

@inproceedings{almutairi_instance_2019,
	title = {Instance segmentation of newspaper elements using mask {R}-{CNN}},
	booktitle = {2019 18th {IEEE} {International} {Conference} {On} {Machine} {Learning} {And} {Applications} ({ICMLA})},
	publisher = {IEEE},
	author = {Almutairi, Abdullah and Almashan, Meshal},
	year = {2019},
	keywords = {HEMDIG FRAMEWORK, newspapers, OCR, semantic segmentation, article segmentation},
	pages = {1371--1375},
	file = {almutairi_almashan_2019_instance segmentation of newspaper elements using mask r-cnn.pdf:/home/ebn/pCloudDrive/zot_library/IEEE/2019/almutairi_almashan_2019_instance segmentation of newspaper elements using mask r-cnn.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/34UDX7UG/8999273.html:text/html},
}

@inproceedings{wieser_layout_1993,
	title = {Layout and analysis: finding text, titles, and photos in {Digital} {Images} of {Newspaper} pages},
	shorttitle = {Layout and analysis},
	booktitle = {Proceedings of 2nd {International} {Conference} on {Document} {Analysis} {And} {Recognition} ({ICDAR}'93)},
	publisher = {IEEE},
	author = {Wieser, Johann and Pinz, Axel},
	year = {1993},
	keywords = {HEMDIG FRAMEWORK, layout analysis, newspapers, layout segmentation},
	pages = {774--777},
	file = {Snapshot:/home/ebn/Zotero/storage/QNDAC5HE/395623.html:text/html;wieser_pinz_1993_layout and analysis.pdf:/home/ebn/pCloudDrive/zot_library/IEEE/1993/wieser_pinz_1993_layout and analysis.pdf:application/pdf},
}

@article{koistinen_how_2017,
	title = {How to improve optical character recognition of historical {Finnish} newspapers using open source {Tesseract} {OCR} engine},
	journal = {Proc. of LTC},
	author = {Koistinen, Mika and Kettunen, Kimmo and Kervinen, Jukka},
	year = {2017},
	keywords = {HEMDIG FRAMEWORK, newspapers, OCR, tesseract},
	pages = {279--283},
	file = {koistinenet al_2017_how to improve optical character recognition of historical.pdf:/home/ebn/pCloudDrive/zot_library/Proc. of LTC/2017/koistinenet al_2017_how to improve optical character recognition of historical.pdf:application/pdf},
}

@inproceedings{lee_newspaper_2020,
	title = {The newspaper navigator dataset: extracting headlines and visual content from 16 million historic newspaper pages in chronicling {America}},
	shorttitle = {The newspaper navigator dataset},
	booktitle = {Proceedings of the 29th {ACM} {International} {Conference} on {Information} \& {Knowledge} {Management}},
	author = {Lee, Benjamin Charles Germain and Mears, Jaime and Jakeway, Eileen and Ferriter, Meghan and Adams, Chris and Yarasavage, Nathan and Thomas, Deborah and Zwaard, Kate and Weld, Daniel S.},
	year = {2020},
	keywords = {HEMDIG FRAMEWORK, image segmentation, newspapers, OCR},
	pages = {3055--3062},
	file = {leeet al_2020_the newspaper navigator dataset.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2020/leeet al_2020_the newspaper navigator dataset.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/SC6RGEZ5/3340531.html:text/html},
}

@article{lee_newspaper_2020-1,
	title = {The newspaper navigator dataset: extracting and analyzing visual content from 16 million historic newspaper pages in chronicling {America}},
	shorttitle = {The newspaper navigator dataset},
	journal = {arXiv preprint arXiv:2005.01583},
	author = {Lee, Benjamin Charles Germain and Mears, Jaime and Jakeway, Eileen and Ferriter, Meghan and Adams, Chris and Yarasavage, Nathan and Thomas, Deborah and Zwaard, Kate and Weld, Daniel S.},
	year = {2020},
	keywords = {HEMDIG FRAMEWORK, image segmentation, newspapers, visual analysis tools},
	file = {leeet al_2020_the newspaper navigator dataset.pdf:/home/ebn/pCloudDrive/zot_library/arXiv preprint arXiv2005.01583/2020/leeet al_2020_the newspaper navigator dataset.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/7KJGKX36/2005.html:text/html},
}

@article{paakkonen_exporting_2016,
	title = {Exporting {Finnish} digitized historical newspaper contents for offline use},
	volume = {22},
	number = {7/8},
	journal = {D-Lib Magazine},
	author = {Pääkkönen, Tuula and Kervinen, Jukka and Nivala, Asko and Kettunen, Kimmo and Mäkelä, Eetu},
	year = {2016},
	note = {Publisher: Corporation for National Research Initiatives},
	keywords = {ALTO XML, HEMDIG FRAMEWORK, newspapers},
	pages = {1--9},
	file = {Full Text:/home/ebn/Zotero/storage/36LF9TPL/07paakkonen.print.html:text/html},
}

@inproceedings{allen_framework_2007,
	title = {A framework for text processing and supporting access to collections of digitized historical newspapers},
	booktitle = {Symposium on {Human} {Interface} and the {Management} of {Information}},
	publisher = {Springer},
	author = {Allen, Robert B. and Japzon, Andrea and Achananuparp, Palakorn and Lee, Ki Jung},
	year = {2007},
	keywords = {framework, HEMDIG FRAMEWORK, newspapers, text processing},
	pages = {235--244},
	file = {allenet al_2007_a framework for text processing and supporting access to.pdf:/home/ebn/pCloudDrive/zot_library/Springer/2007/allenet al_2007_a framework for text processing and supporting access to.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/IT2VBWBY/978-3-540-73354-6_26.html:text/html},
}

@article{hengchen_data-driven_2021,
	title = {A data-driven approach to studying changing vocabularies in historical newspaper collections},
	volume = {36},
	issn = {2055-7671},
	url = {https://doi.org/10.1093/llc/fqab032},
	doi = {10.1093/llc/fqab032},
	abstract = {Nation and nationhood are among the most frequently studied concepts in the field of intellectual history. At the same time, the word ‘nation’ and its historical usage are very vague. The aim in this article was to develop a data-driven method using dependency parsing and neural word embeddings to clarify some of the vagueness in the evolution of this concept. To this end, we propose the following two-step method. First, using linguistic processing, we create a large set of words pertaining to the topic of nation. Second, we train diachronic word embeddings and use them to quantify the strength of the semantic similarity between these words and thereby create meaningful clusters, which are then aligned diachronically. To illustrate the robustness of the study across languages, time spans, as well as large datasets, we apply it to the entirety of five historical newspaper archives in Dutch, Swedish, Finnish, and English. To our knowledge, thus far there have been no large-scale comparative studies of this kind that purport to grasp long-term developments in as many as four different languages in a data-driven way. A particular strength of the method we describe in this article is that, by design, it is not limited to the study of nationhood, but rather expands beyond it to other research questions and is reusable in different contexts.},
	number = {Supplement\_2},
	urldate = {2021-11-29},
	journal = {Digital Scholarship in the Humanities},
	author = {Hengchen, Simon and Ros, Ruben and Marjanen, Jani and Tolonen, Mikko},
	month = oct,
	year = {2021},
	keywords = {data-driven method, HEMDIG FRAMEWORK, newspapers, word embedding},
	pages = {ii109--ii126},
	file = {hengchen_et_al_2021_a_data-driven_approach_to_studying_changing_vocabularies_in_historical.pdf:/home/ebn/pCloudDrive/zot_library/Digital Scholarship in the Humanities/2021/hengchen_et_al_2021_a_data-driven_approach_to_studying_changing_vocabularies_in_historical.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/WSGXJITP/6421793.html:text/html},
}

@inproceedings{richter_low-resource_2018,
	address = {Miyazaki, Japan},
	title = {Low-resource {Post} {Processing} of {Noisy} {OCR} {Output} for {Historical} {Corpus} {Digitisation}},
	url = {https://aclanthology.org/L18-1369},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2018)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Richter, Caitlin and Wickes, Matthew and Beser, Deniz and Marcus, Mitch},
	month = may,
	year = {2018},
	keywords = {faroese corpus, HEMDIG FRAMEWORK, OCR, OCR error correction, post processing},
	file = {richteret al_2018_low-resource post processing of noisy ocr output for.pdf:/home/ebn/pCloudDrive/zot_library/European Language Resources Association (ELRA)/2018/richteret al_2018_low-resource post processing of noisy ocr output for.pdf:application/pdf},
}

@inproceedings{bayomi_c-hts_2018,
	address = {Miyazaki, Japan},
	title = {C-{HTS}: {A} {Concept}-based {Hierarchical} {Text} {Segmentation} approach},
	url = {https://aclanthology.org/L18-1241},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2018)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Bayomi, Mostafa and Lawless, Séamus},
	month = may,
	year = {2018},
	keywords = {c-hts, digital tool, HEMDIG FRAMEWORK, text segmentation, wikipedia},
	file = {bayomi_lawless_2018_c-hts.pdf:/home/ebn/pCloudDrive/zot_library/European Language Resources Association (ELRA)/2018/bayomi_lawless_2018_c-hts.pdf:application/pdf},
}

@inproceedings{ferres_pdfdigest_2018,
	address = {Miyazaki, Japan},
	title = {{PDFdigest}: an {Adaptable} {Layout}-{Aware} {PDF}-to-{XML} {Textual} {Content} {Extractor} for {Scientific} {Articles}},
	url = {https://aclanthology.org/L18-1298},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2018)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Ferrés, Daniel and Saggion, Horacio and Ronzano, Francesco and Bravo, Àlex},
	month = may,
	year = {2018},
	keywords = {digital tool, HEMDIG FRAMEWORK, layout segmentation, OCR, PDF, pdfdigest, text mining},
	file = {ferréset al_2018_pdfdigest.pdf:/home/ebn/pCloudDrive/zot_library/European Language Resources Association (ELRA)/2018/ferréset al_2018_pdfdigest.pdf:application/pdf},
}

@inproceedings{schabus_academic-industrial_2018,
	address = {Miyazaki, Japan},
	title = {Academic-{Industrial} {Perspective} on the {Development} and {Deployment} of a {Moderation} {System} for a {Newspaper} {Website}},
	url = {https://aclanthology.org/L18-1253},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2018)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Schabus, Dietmar and Skowron, Marcin},
	month = may,
	year = {2018},
	keywords = {HEMDIG FRAMEWORK, information retrieval, newspapers, NLP, websites},
	file = {schabus_skowron_2018_academic-industrial perspective on the development and.pdf:/home/ebn/pCloudDrive/zot_library/European Language Resources Association (ELRA)/2018/schabus_skowron_2018_academic-industrial perspective on the development and.pdf:application/pdf},
}

@inproceedings{kisler_mocca_2018,
	address = {Miyazaki, Japan},
	title = {{MOCCA}: {Measure} of {Confidence} for {Corpus} {Analysis} - {Automatic} {Reliability} {Check} of {Transcript} and {Automatic} {Segmentation}},
	url = {https://aclanthology.org/L18-1281},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2018)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Kisler, Thomas and Schiel, Florian},
	month = may,
	year = {2018},
	keywords = {automatic segmentation, clarin, digital tool, HEMDIG FRAMEWORK, mocca},
	file = {kisler_schiel_2018_mocca.pdf:/home/ebn/pCloudDrive/zot_library/European Language Resources Association (ELRA)/2018/kisler_schiel_2018_mocca.pdf:application/pdf},
}

@inproceedings{moreau_multilingual_2018,
	address = {Miyazaki, Japan},
	title = {Multilingual {Word} {Segmentation}: {Training} {Many} {Language}-{Specific} {Tokenizers} {Smoothly} {Thanks} to the {Universal} {Dependencies} {Corpus}},
	url = {https://aclanthology.org/L18-1180},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2018)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Moreau, Erwan and Vogel, Carl},
	month = may,
	year = {2018},
	keywords = {HEMDIG FRAMEWORK, multilingual, tokenization, word segmentation},
	file = {moreau_vogel_2018_multilingual word segmentation.pdf:/home/ebn/pCloudDrive/zot_library/European Language Resources Association (ELRA)/2018/moreau_vogel_2018_multilingual word segmentation.pdf:application/pdf},
}

@inproceedings{nastase_correction_2018,
	address = {Miyazaki, Japan},
	title = {Correction of {OCR} {Word} {Segmentation} {Errors} in {Articles} from the {ACL} {Collection} through {Neural} {Machine} {Translation} {Methods}},
	url = {https://aclanthology.org/L18-1113},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2018)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Nastase, Vivi and Hitschler, Julian},
	month = may,
	year = {2018},
	keywords = {acl collection, HEMDIG FRAMEWORK, neural machine translation, OCR, OCR error correction, word segmentation},
	file = {nastase_hitschler_2018_correction of ocr word segmentation errors in articles from.pdf:/home/ebn/pCloudDrive/zot_library/European Language Resources Association (ELRA)/2018/nastase_hitschler_2018_correction of ocr word segmentation errors in articles from.pdf:application/pdf},
}

@book{thylstrup_politics_2019,
	edition = {Hardcover},
	title = {The {Politics} of {Mass} {Digitization}},
	isbn = {978-0-262-03901-7},
	url = {http://gen.lib.rus.ec/book/index.php?md5=a12039dbff20746c39314db8cc459920},
	urldate = {2021-10-06},
	publisher = {The MIT Press},
	author = {Thylstrup, Nanna Bonde},
	year = {2019},
	keywords = {europeana, google books, HEMDIG FRAMEWORK, large-scale digitization},
	file = {thylstrup_2019_the_politics_of_mass_digitization.pdf:/home/ebn/pCloudDrive/zot_library/The MIT Press/2019/thylstrup_2019_the_politics_of_mass_digitization.pdf:application/pdf},
}

@article{jarlbrink_cultural_2017,
	title = {Cultural heritage as digital noise: nineteenth century newspapers in the digital archive},
	volume = {73},
	issn = {0022-0418},
	shorttitle = {Cultural heritage as digital noise},
	url = {https://www.emerald.com/insight/content/doi/10.1108/JD-09-2016-0106/full/html},
	doi = {10.1108/JD-09-2016-0106},
	abstract = {Purpose
              The purpose of this paper is to explore and analyze the digitized newspaper collection at the National Library of Sweden, focusing on cultural heritage as digital noise. In what specific ways are newspapers transformed in the digitization process? If the digitized document is not the same as the source document – is it still a historical record, or is it transformed into something else?
            
            
              Design/methodology/approach
              
                The authors have analyzed the XML files from
                Aftonbladet
                1830 to 1862. The most frequent newspaper words not matching a high-quality references corpus were selected to zoom in on the noisiest part of the paper. The variety of the interpretations generated by optical character recognition (OCR) was examined, as well as texts generated by auto-segmentation. The authors have made a limited ethnographic study of the digitization process.
              
            
            
              Findings
              
                The research shows that the digital collection of
                Aftonbladet
                contains extreme amounts of noise: millions of misinterpreted words generated by OCR, and millions of texts re-edited by the auto-segmentation tool. How the tools work is mostly unknown to the staff involved in the digitization process? Sticking to any idea of a provenance chain is hence impossible, since many steps have been outsourced to unknown factors affecting the source document.
              
            
            
              Originality/value
              The detail examination of digitally transformed newspapers is valuable to scholars depending on newspaper databases in their research. The paper also highlights the fact that libraries outsourcing digitization processes run the risk of losing control over the quality of their collections.},
	language = {en},
	number = {6},
	urldate = {2021-09-15},
	journal = {Journal of Documentation},
	author = {Jarlbrink, Johan and Snickars, Pelle},
	month = oct,
	year = {2017},
	keywords = {article segmentation, cultural heritage, HEMDIG FRAMEWORK, large-scale digitization, newspapers, OCR, XML},
	pages = {1228--1243},
	file = {jarlbrink_snickars_2017_cultural_heritage_as_digital_noise.pdf:/home/ebn/pCloudDrive/zot_library/Journal of Documentation/2017/jarlbrink_snickars_2017_cultural_heritage_as_digital_noise.pdf:application/pdf},
}

@inproceedings{ehrmann_historical_2017,
	address = {Athens, Greece},
	title = {Historical {Newspaper} {User} {Interfaces}: {A} {Review}},
	copyright = {cc\_by\_4},
	shorttitle = {Historical {Newspaper} {User} {Interfaces}},
	url = {http://library.ifla.org/id/eprint/2578/},
	abstract = {After decades of large-scale digitization, many historical newspaper collections are just one click away via online portals developed and supported by various public or private stakeholders. Initially offering access to full text search and facsimiles visualization only, historic newspaper user interfaces are increasingly integrating advanced exploration features based on the application of text mining tools to digitized sources. As gateways to enriched material, such interfaces are however not neutral and play a fundamental role in how users perceive historical sources, understand potential biases of upstream processes and benefit from the opportunities of datafication. What features can be found in current interfaces, and to what degree do interfaces adopt novel technologies? This paper presents a survey of interfaces for digitized historical newspapers with the aim of mapping the current state of the art and identifying recent trends with regard to content presentation, enrichment and user interaction. We devised 6 interface assessment criteria and reviewed twenty-four interfaces based on ca. 140 predefined features.},
	language = {en},
	urldate = {2021-09-14},
	booktitle = {Libraries: dialogue for change},
	author = {Ehrmann, Maud and Bunout, Estelle and Düring, Marten},
	year = {2017},
	keywords = {GUI, HEMDIG FRAMEWORK, newspapers},
	file = {085-ehrmann-en.pdf:/home/ebn/Zotero/storage/3FEHW793/085-ehrmann-en.pdf:application/pdf;ehrmann_et_al_2017_historical_newspaper_user_interfaces.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2017/ehrmann_et_al_2017_historical_newspaper_user_interfaces.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/HIMKUPER/2578.html:text/html},
}

@article{baker_preservar_2021,
	title = {Preservar os seus dados de investigação},
	issn = {2753-9296},
	url = {https://programminghistorian.org/pt/licoes/preservar-os-seus-dados-de-investigacao},
	doi = {10.46430/phpt0001},
	abstract = {Esta lição irá sugerir maneiras pelas quais os historiadores podem documentar e estruturar os seus dados de pesquisa, a fim de garantir que continuem sendo acessíveis no futuro.},
	language = {pt},
	number = {1},
	urldate = {2021-05-12},
	journal = {The Programming Historian em português},
	author = {Baker, James},
	editor = {Crymble, Adam and Paulino, Joana Vieira},
	translator = {Cavalcanti, Márcia T.},
	collaborator = {Winters, Jane and Howard, Sharon and Turkel, William J. and Guedes, Maria and Freire, Elizabeth},
	month = jan,
	year = {2021},
	keywords = {HEMDIG FRAMEWORK, data management},
}

@book{sekine_named_2004,
	title = {Named entity: {History} and future},
	shorttitle = {Named entity},
	author = {Sekine, Satoshi},
	year = {2004},
	keywords = {HEMDIG FRAMEWORK, NER},
	file = {Full Text:/home/ebn/Zotero/storage/5TRCV8P5/Sekine - 2004 - Named entity History and future.pdf:application/pdf},
}

@inproceedings{martinek_hybrid_2019,
	title = {Hybrid {Training} {Data} for {Historical} {Text} {OCR}},
	doi = {10.1109/ICDAR.2019.00096},
	abstract = {Current optical character recognition (OCR) systems commonly make use of recurrent neural networks (RNN) that process whole text lines. Such systems avoid the task of character segmentation necessary for character-based approaches. A disadvantage of this approach is a need of a large amount of annotated data. This can be solved by sing generated synthetic data instead of costly manually annotated ones. Unfortunately, such data is often not suitable for historical documents particularly for quality reasons. This work presents a hybrid approach for generating annotated data for OCR at a low cost. We first collect a small dataset of isolated characters from historical document images. Then, we generate historical looking text lines from the generated characters. Another contribution lies in the design and implementation of an OCR system based on a convolutional-LSTM network. We first pre-train this system on hybrid data. Afterwards, the network is fine-tuned with real printed text lines. We demonstrate that this training strategy is efficient for obtaining state-of-the-art results. We also show that the score of the proposed system is comparable or even better in comparison to several state-of-the-art systems.},
	booktitle = {2019 {International} {Conference} on {Document} {Analysis} and {Recognition} ({ICDAR})},
	author = {Martínek, J. and Lenc, L. and Král, P. and Nicolaou, A. and Christlein, V.},
	month = sep,
	year = {2019},
	note = {ISSN: 2379-2140},
	keywords = {annotated data, character segmentation, character-based approaches, CNN, Hybrid Training, Historical Documents, LSTM, Neural Networks, OCR, convolutional-LSTM network, document image processing, generated characters, HEMDIG FRAMEWORK, historical document images, historical documents, historical looking text lines, historical text OCR, history, hybrid data, Hybrid power systems, hybrid training data, image segmentation, Image segmentation, isolated characters, learning (artificial intelligence), natural language processing, neural networks, OCR, OCR system, optical character recognition, Optical character recognition software, optical character recognition systems, printed text lines, quality reasons, recurrent neural nets, recurrent neural networks, Recurrent neural networks, text analysis, Text recognition, Tools, Training, training strategy},
	pages = {565--570},
	file = {IEEE Xplore Abstract Record:/home/ebn/Zotero/storage/JAYHNVQV/8978139.html:text/html;martínek_et_al_2019_hybrid_training_data_for_historical_text_ocr.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2019/martínek_et_al_2019_hybrid_training_data_for_historical_text_ocr.pdf:application/pdf},
}

@article{souza_portuguese_2020,
	title = {Portuguese {Named} {Entity} {Recognition} using {BERT}-{CRF}},
	url = {http://arxiv.org/abs/1909.10649},
	abstract = {Recent advances in language representation using neural networks have made it viable to transfer the learned internal states of a trained model to downstream natural language processing tasks, such as named entity recognition (NER) and question answering. It has been shown that the leverage of pre-trained language models improves the overall performance on many tasks and is highly beneficial when labeled data is scarce. In this work, we train Portuguese BERT models and employ a BERT-CRF architecture to the NER task on the Portuguese language, combining the transfer capabilities of BERT with the structured predictions of CRF. We explore feature-based and fine-tuning training strategies for the BERT model. Our fine-tuning approach obtains new state-of-the-art results on the HAREM I dataset, improving the F1-score by 1 point on the selective scenario (5 NE classes) and by 4 points on the total scenario (10 NE classes).},
	urldate = {2020-11-09},
	journal = {arXiv:1909.10649 [cs]},
	author = {Souza, Fábio and Nogueira, Rodrigo and Lotufo, Roberto},
	month = feb,
	year = {2020},
	note = {arXiv: 1909.10649},
	keywords = {HEMDIG FRAMEWORK, NER, BERT, machine learning, information retrieval, portuguese},
	file = {souza_et_al_2020_portuguese_named_entity_recognition_using_bert-crf.pdf:/home/ebn/pCloudDrive/zot_library/arXiv1909.10649 [cs]/2020/souza_et_al_2020_portuguese_named_entity_recognition_using_bert-crf.pdf:application/pdf},
}

@book{dandrea_pesquisando_2020,
	title = {Pesquisando plataformas online: conceitos e métodos},
	isbn = {9786556300092},
	shorttitle = {Pesquisando plataformas online},
	url = {http://repositorio.ufba.br/ri/handle/ri/32043},
	abstract = {A obra visa introduzir os Estudos de Plataforma, um campo de estudos que, desde o início da década de 2010, discute as especificidades políticas e materiais das mídias sociais e de outras plataformas online. Datificação, 
algoritmos, governança e os modelos de negócio das plataformas são algumas das dimensões sintetizadas no livro. De modo didático, o autor apresenta um conjunto de leituras e de experimentações metodológicas conduzidas com um diversificado grupo de colaboradoras(es) no país e no exterior.},
	language = {pt\_BR},
	urldate = {2020-10-02},
	publisher = {EDUFBA},
	author = {d’Andréa, Carlos Frederico de Brito},
	year = {2020},
	note = {Accepted: 2020-07-15T14:57:15Z},
	keywords = {HEMDIG FRAMEWORK, plataforms},
	file = {d’andréa_2020_pesquisando plataformas online.pdf:/home/ebn/pCloudDrive/zot_library/EDUFBA/2020/d’andréa_2020_pesquisando plataformas online.pdf:application/pdf;pesquisando-plataformas-online (2).epub:/home/ebn/Zotero/storage/7RK29FVD/pesquisando-plataformas-online (2).epub:application/epub+zip;Snapshot:/home/ebn/Zotero/storage/SJCFIDAS/32043.html:text/html},
}

@inproceedings{fernandes_applying_2018,
	title = {Applying {Deep} {Neural} {Networks} to {Named} {Entity} {Recognition} in {Portuguese} {Texts}},
	booktitle = {2018 {Fifth} {International} {Conference} on {Social} {Networks} {Analysis}, {Management} and {Security} ({SNAMS})},
	publisher = {IEEE},
	author = {Fernandes, Ivo and Cardoso, Henrique Lopes and Oliveira, Eugenio},
	year = {2018},
	keywords = {HEMDIG FRAMEWORK, NER, portuguese, deep neural networks},
	pages = {284--289},
	file = {fernandeset al_2018_applying deep neural networks to named entity recognition.pdf:/home/ebn/pCloudDrive/zot_library/IEEE/2018/fernandeset al_2018_applying deep neural networks to named entity recognition.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/NV7RAQNA/8554782.html:text/html},
}

@inproceedings{dinarelli_tree-structured_2012,
	title = {Tree-structured named entity recognition on ocr data: {Analysis}, processing and results},
	shorttitle = {Tree-structured named entity recognition on ocr data},
	author = {Dinarelli, Marco and Rosset, Sophie},
	year = {2012},
	keywords = {HEMDIG FRAMEWORK, newspapers, OCR, NER, OCR error correction},
	file = {dinarelli_rosset_2012_tree-structured named entity recognition on ocr data.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2012/dinarelli_rosset_2012_tree-structured named entity recognition on ocr data.pdf:application/pdf;Full Text:/home/ebn/Zotero/storage/DUJCLWNL/Dinarelli e Rosset - 2012 - Tree-structured named entity recognition on ocr da.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/BWEHHK29/hal-01490004.html:text/html},
}

@incollection{mugnaini_new_2020,
	address = {Cham},
	title = {A {New} {Entity} {Extraction} {Model} {Based} on {Journalistic} {Brazilian} {Portuguese} {Language} to {Enhance} {Named} {Entity} {Recognition}},
	volume = {319},
	isbn = {978-3-030-50071-9 978-3-030-50072-6},
	url = {http://link.springer.com/10.1007/978-3-030-50072-6_5},
	language = {en},
	urldate = {2020-09-25},
	booktitle = {Data and {Information} in {Online} {Environments}},
	publisher = {Springer International Publishing},
	author = {de Aquino Silva, Rogerio and da Silva, Luana and Dutra, Moisés Lima and de Araujo, Gustavo Medeiros},
	editor = {Mugnaini, Rogério},
	year = {2020},
	doi = {10.1007/978-3-030-50072-6_5},
	note = {Series Title: Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering},
	keywords = {HEMDIG FRAMEWORK, NER, NLP, portuguese, brazilian portuguese, entity extraction model},
	pages = {53--63},
	file = {de aquino silvaet al_2020_a new entity extraction model based on journalistic.pdf:/home/ebn/pCloudDrive/zot_library/Springer International Publishing/2020/de aquino silvaet al_2020_a new entity extraction model based on journalistic.pdf:application/pdf},
}

@incollection{morzy_improving_2015,
	address = {Cham},
	title = {Improving {Retrieval} of {Historical} {Content} with {Entity} {Linking}},
	volume = {539},
	isbn = {978-3-319-23200-3 978-3-319-23201-0},
	url = {http://link.springer.com/10.1007/978-3-319-23201-0_50},
	language = {en},
	urldate = {2020-09-25},
	booktitle = {New {Trends} in {Databases} and {Information} {Systems}},
	publisher = {Springer International Publishing},
	author = {De Wilde, Max},
	editor = {Morzy, Tadeusz and Valduriez, Patrick and Bellatreche, Ladjel},
	year = {2015},
	doi = {10.1007/978-3-319-23201-0_50},
	note = {Series Title: Communications in Computer and Information Science},
	keywords = {HEMDIG FRAMEWORK, NER, entity linking},
	pages = {498--504},
}

@article{goyal_recent_2018,
	title = {Recent named entity recognition and classification techniques: a systematic review},
	volume = {29},
	shorttitle = {Recent named entity recognition and classification techniques},
	journal = {Computer Science Review},
	author = {Goyal, Archana and Gupta, Vishal and Kumar, Manish},
	year = {2018},
	note = {Publisher: Elsevier},
	keywords = {HEMDIG FRAMEWORK, NER},
	pages = {21--43},
}

@article{huilin_overview_2010,
	title = {Overview on the advance of the research on named entity recognition},
	volume = {26},
	number = {6},
	journal = {Data Analysis and Knowledge Discovery},
	author = {Huilin, Sun Zhen Wang},
	year = {2010},
	keywords = {HEMDIG FRAMEWORK, NER},
	pages = {42--47},
	file = {Full Text:/home/ebn/Zotero/storage/D4SIXGHU/Huilin - 2010 - Overview on the advance of the research on named e.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/9PSQJSB8/abstract3231.html:text/html},
}

@inproceedings{rodriquez_comparison_2012,
	title = {Comparison of named entity recognition tools for raw {OCR} text.},
	booktitle = {Konvens},
	author = {Rodriquez, Kepa Joseba and Bryant, Mike and Blanke, Tobias and Luszczynska, Magdalena},
	year = {2012},
	keywords = {HEMDIG FRAMEWORK, OCR, NER, european holocaust research infrastructure},
	pages = {410--414},
	file = {rodriquez_et_al_2012_comparison_of_named_entity_recognition_tools_for_raw_ocr_text.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2012/rodriquez_et_al_2012_comparison_of_named_entity_recognition_tools_for_raw_ocr_text.pdf:application/pdf},
}

@inproceedings{bon_challenges_2019,
	address = {New York, NY, USA},
	series = {{DATeCH2019}},
	title = {Challenges of {Mass} {OCR}-isation of {Medieval} {Latin} {Texts} in a {Resource}-{Limited} {Project}},
	isbn = {978-1-4503-7194-0},
	url = {https://doi.org/10.1145/3322905.3322925},
	doi = {10.1145/3322905.3322925},
	abstract = {This paper aims to present the first stage of the ANR project VELUM (Towards Innovative Ways of Visualising, Exploring and Linking Resources for Medieval Latin) which, by 2022, is intended to compile the largest representative corpus of Medieval Latin texts. The corpus, which is to comprise 150 millions tokens, is expected to provide selected texts from four centuries of Latin written production (from 800 to 1200 AD) from all across Europe. It will also cover a wide gamut of genres from theological texts to historiography, to documents and letters. In the first stage of the project, that started in the mid-2018, we are selecting the texts to be included in the corpus, basing on the metadata in the electronic database of Medieval Latin texts that is, at the moment, the largest scholarly-driven source of information of this kind available free on the Internet. Once selected, the texts are retrieved from existing collections and digital libraries. As early tests showed, less than a half of the texts already exist in interoperable formats such as TEI XML, or at least in a form that allows for easy conversion which does not require human intervention. This means that the bulk of the corpus texts has to be acquired from digital images of editions available on-line through OCR and post-processing. For both tasks, there now exists a broad range of efficient tools, and many sophisticated workflows were proposed in literature. However, the presented project is significantly limited when it comes to its resources, since one person is expected to work on controlling the process and improving OCR quality during a single year. In the presentation we would like, first, to demonstrate the workflow of the project which, at the moment, consists of the 1) image extraction from PDF files, 2) image cleaning, and its subsequent 3) OCR, followed by 4) the batch-correction of the OCR errors, and 5) the removal of the non-Latin text with a simple classifier. The tools we use are all free and open source, an important factor in a project which is low on resources but ambitious in its goals. The PDF extraction and conversion are performed with Linux 'convert' and 'pdfimages' commands. The output TIFFs are cleaned with the "ScanTailor", while the OCR is realised with "Tesseract". To save on time, the entire workflow is automated, with the human analyst verifying the quality of the output and mass-correcting OCR errors with the "Post Correction Tool". Apart from presenting the project and the workflow, the paper will discuss the challenges we have faced. One of the most problematic issues turned out to be the relatively disparate quality of the image files retrieved from online sources. Another factor that significantly hinders the automatic processing was the quality of text editions.},
	urldate = {2021-01-04},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Digital} {Access} to {Textual} {Cultural} {Heritage}},
	publisher = {Association for Computing Machinery},
	author = {Bon, Bruno and Nowak, Krzysztof and ra Vangone, Lau},
	month = may,
	year = {2019},
	keywords = {HEMDIG FRAMEWORK, OCR, corpus, image processing, OCR error correction, Latin, velum project},
	pages = {81--85},
	file = {bonet al_2019_challenges of mass ocr-isation of medieval latin texts in a.pdf:/home/ebn/pCloudDrive/zot_library/Association for Computing Machinery/2019/bonet al_2019_challenges of mass ocr-isation of medieval latin texts in a.pdf:application/pdf},
}

@article{bolick_digital_2006,
	title = {Digital {Archives}: {Democratizing} the {Doing} of {History} · {Digital} {Archiving} {Resources}},
	volume = {21},
	url = {https://dar.cah.ucf.edu/items/show/44},
	abstract = {This article discusses the fact that prior to the digital revolution, only scholars could study primary sources. K-12 students and teachers were relegated to the little they could get to locally because they did not have the money needed to experience primary historical sources themselves. These limitations kept many students and teachers from getting excited about research. Digital archives, however, allow anyone access to primary sources in a nonlinear environment. Because of this, archivists should strive to create digital archives from a large variety of voices. In this way, the history classroom should be radically changed to foster historical inquiry and personal connections to historical content. The article discusses a study of pre-service teachers who engaged with digital archives. They found them useful for their future classrooms, especially since they often represented the marginalized groups not represented in the textbook.},
	number = {1},
	urldate = {2021-01-05},
	journal = {International Journal of Social Education},
	author = {Bolick, Cheryl Mason},
	year = {2006},
	keywords = {digital archives, HEMDIG FRAMEWORK},
	pages = {122--134},
	file = {bolick_2006_digital_archives.pdf:/home/ebn/pCloudDrive/zot_library/International Journal of Social Education/2006/bolick_2006_digital_archives.pdf:application/pdf;Digital Archives\: Democratizing the Doing of History · Digital Archiving Resources:/home/ebn/Zotero/storage/XRJ5LB4F/44.html:text/html},
}

@inproceedings{bukhari_anyocr_2017,
	title = {{anyOCR}: {An} {Open}-{Source} {OCR} {System} for {Historical} {Archives}},
	volume = {01},
	shorttitle = {{anyOCR}},
	doi = {10.1109/ICDAR.2017.58},
	abstract = {Currently an intensive amount of research is going on in the field of digitizing historical archives for converting scanned document images into searchable full text. This paper presents the "anyOCR" system which mainly emphasize the techniques requires for digitizing a historical archive with high accuracy. It is an open-source system for the research community who can easily apply the anyOCR system for digitizing historical archives. The anyOCR system supports a complete document processing pipeline, which includes layout analysis, training OCR models and text line prediction, with an addition of intelligent and interactive layout and OCR error corrections web applications. The anyOCR system can also be used for contemporary document images containing diverse, simple to complex, layouts. This paper describes the current state of the anyOCR system, its architecture, as well as its major features. This paper also provides information about the availability, documentation, and tutorials of the anyOCR system.},
	booktitle = {2017 14th {IAPR} {International} {Conference} on {Document} {Analysis} and {Recognition} ({ICDAR})},
	author = {Bukhari, S. S. and Kadi, A. and Jouneh, M. A. and Mir, F. M. and Dengel, A.},
	month = nov,
	year = {2017},
	note = {ISSN: 2379-2140},
	keywords = {anyOCR system, contemporary document images, document image processing, document processing pipeline, End-To-End Document Image Processing, error correction, HEMDIG FRAMEWORK, historical archives, Historical Archives, historical archives digitization, history, image processing, Image segmentation, Internet, Layout, layout analysis, OCR, OCR error corrections web applications, OCR System, open-source OCR system, optical character recognition, Optical character recognition software, Particle separators, Pipelines, public domain software, scanned document images, searchable full text, text line prediction, Text recognition, Training},
	pages = {305--310},
	file = {bukhari_et_al_2017_anyocr.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2017/bukhari_et_al_2017_anyocr.pdf:application/pdf;IEEE Xplore Abstract Record:/home/ebn/Zotero/storage/PZ5RQ3IJ/8269989.html:text/html},
}

@inproceedings{neudecker_ocr-d_2019,
	address = {New York, NY, USA},
	series = {{DATeCH2019}},
	title = {{OCR}-{D}: {An} end-to-end open source {OCR} framework for historical printed documents},
	isbn = {978-1-4503-7194-0},
	shorttitle = {{OCR}-{D}},
	url = {https://doi.org/10.1145/3322905.3322917},
	doi = {10.1145/3322905.3322917},
	abstract = {Various research projects were concerned with the development and adaptation of methods for OCR specifically for historical printed documents (cf. METAe [20], IMPACT [1], eMOP [9]). However, these initiatives have ended before the wide adoption of deep neural networks and, despite the various project's achievements, there remains a lack of OCR software that is a) comprehensive with regard to the challenges presented by the wide variety of historical documents and b) available as ready-to-use Free Software. The OCR-D project aims to rectify that. In this paper we introduce the background of OCR-D, the main challenges and shortcomings in the availability of open tools and resources for OCR of historical printed documents and discuss the various software modules and related components (repositories, workflows) that are being made available through OCR-D. Finally we provide an outlook to a number of remaining challenges that are not addressed by OCR-D and point out several examples for the positive community aspects arisen through the creation and sharing of open resources for historical German OCR.},
	urldate = {2021-01-05},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Digital} {Access} to {Textual} {Cultural} {Heritage}},
	publisher = {Association for Computing Machinery},
	author = {Neudecker, Clemens and Baierer, Konstantin and Federbusch, Maria and Boenig, Matthias and Würzner, Kay-Michael and Hartmann, Volker and Herrmann, Elisa},
	month = may,
	year = {2019},
	keywords = {digital libraries, digitization, framework, HEMDIG FRAMEWORK, historical prints, OCR, ocr-d, open source, optical character recognition},
	pages = {53--58},
	file = {neudecker_et_al_2019_ocr-d.pdf:/home/ebn/pCloudDrive/zot_library/Association for Computing Machinery/2019/neudecker_et_al_2019_ocr-d.pdf:application/pdf},
}

@article{islam_survey_2017,
	title = {A {Survey} on {Optical} {Character} {Recognition} {System}},
	url = {http://arxiv.org/abs/1710.05703},
	abstract = {Optical Character Recognition (OCR) has been a topic of interest for many years. It is defined as the process of digitizing a document image into its constituent characters. Despite decades of intense research, developing OCR with capabilities comparable to that of human still remains an open challenge. Due to this challenging nature, researchers from industry and academic circles have directed their attentions towards Optical Character Recognition. Over the last few years, the number of academic laboratories and companies involved in research on Character Recognition has increased dramatically. This research aims at summarizing the research so far done in the field of OCR. It provides an overview of different aspects of OCR and discusses corresponding proposals aimed at resolving issues of OCR.},
	urldate = {2020-03-09},
	journal = {arXiv:1710.05703 [cs]},
	author = {Islam, Noman and Islam, Zeeshan and Noor, Nazia},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.05703},
	keywords = {HEMDIG FRAMEWORK, OCR, image analysis, survey},
	file = {arXiv.org Snapshot:/home/ebn/Zotero/storage/UZ3ZVHN3/1710.html:text/html;islamet al_2017_a survey on optical character recognition system.pdf:/home/ebn/pCloudDrive/zot_library/arXiv1710.05703 [cs]/2017/islamet al_2017_a survey on optical character recognition system.pdf:application/pdf},
}

@book{chaudhuri_optical_2017,
	edition = {1},
	series = {Studies in {Fuzziness} and {Soft} {Computing} 352},
	title = {Optical {Character} {Recognition} {Systems} for {Different} {Languages} with {Soft} {Computing}},
	isbn = {978-3-319-50251-9},
	urldate = {2020-03-09},
	publisher = {Springer International Publishing},
	author = {Chaudhuri, Arindam and Mandaviya, Krupa and Badelia, Pratixa and Ghosh (auth.), Soumya K.},
	year = {2017},
	keywords = {HEMDIG FRAMEWORK, OCR, digital tool, multilingual},
	file = {chaudhuriet al_2017_optical character recognition systems for different.pdf:/home/ebn/pCloudDrive/zot_library/Springer International Publishing/2017/chaudhuriet al_2017_optical character recognition systems for different.pdf:application/pdf},
}

@book{bebis_advances_2016,
	edition = {1},
	series = {Lecture {Notes} in {Computer} {Science} 10073},
	title = {Advances in {Visual} {Computing}: 12th {International} {Symposium}, {ISVC} 2016, {Las} {Vegas}, {NV}, {USA}, {December} 12-14, 2016, {Proceedings}, {Part} {II}},
	isbn = {978-3-319-50831-3},
	shorttitle = {Advances in {Visual} {Computing}},
	urldate = {2020-03-09},
	publisher = {Springer International Publishing},
	author = {Bebis, George and Boyle, Richard and Parvin, Bahram and Koracin, Darko and Porikli, Fatih and Skaff, Sandra and Entezari, Alireza and Min, Jianyuan and Iwai, Daisuke and Sadagic, Amela and Scheidegger, Carlos and Isenberg (eds.), Tobias},
	year = {2016},
	keywords = {HEMDIG FRAMEWORK},
}

@article{brasil_historia_2020,
	title = {História digital: reflexões a partir da {Hemeroteca} {Digital} {Brasileira} e do uso de {CAQDAS} na reelaboração da pesquisa histórica.},
	volume = {33},
	copyright = {Direitos autorais 2020 Revista Estudos Históricos},
	issn = {2178-1494},
	shorttitle = {História digital},
	url = {http://bibliotecadigital.fgv.br/ojs/index.php/reh/article/view/79933},
	doi = {http://dx.doi.org/10.1590/S2178-14942020000100011},
	abstract = {O presente artigo pretende discutir o papel do uso de ferramentas digitais na pesquisa e na escrita da história, refletindo sobre as transformações e os desafios no modo de produção do conhecimento na prática de investigação da ciência histórica, abordando dois aspectos fundamentais: a) o progressivo uso de fontes de pesquisa provenientes de acervos ou repositórios digitais, por meio da análise da Hemeroteca Digital Brasileira (HDB) da Biblioteca Nacional (BN); e b) a maneira como os aplicativos de análises de dados qualitativos — CAQDAS, acrônimo do inglês computer assisted qualitative data analysis software — podem servir para minimizar os problemas e as limitações gerados pelo uso inadvertido e com pouco rigor metodológico das ferramentas digitais. Aqui, utilizaremos o programa Atlas.ti como exemplo. Concluímos que a busca e a análise digital transformam não apenas a pesquisa histórica, mas possibilitam novas perguntas, problemas e respostas, impactando tanto a teoria quanto o método da disciplina.},
	language = {pt},
	number = {69},
	urldate = {2020-02-04},
	journal = {Revista Estudos Históricos},
	author = {Brasil, Eric and Nascimento, Leonardo Fernandes},
	month = jan,
	year = {2020},
	keywords = {HEMDIG FRAMEWORK, newspapers, Digital history, História digital, HDB, Atlas.ti, Brazilian Digital Newspaper Library, Hemeroteca Digital Brasileira},
	pages = {196--219},
	file = {brasil_nascimento_2020_história_digital.pdf:/home/ebn/pCloudDrive/zot_library/Revista Estudos Históricos/2020/brasil_nascimento_2020_história_digital.pdf:application/pdf},
}

@book{gooding_historic_2017,
	address = {London ; New York},
	series = {Digital {Research} in the {Arts} and {Humanities}},
	title = {Historic newspapers in the digital age: "search all about it!"},
	isbn = {978-1-4724-6338-8},
	shorttitle = {Historic newspapers in the digital age},
	publisher = {Routledge, Taylor \& Francis Group},
	author = {Gooding, Paul},
	year = {2017},
	keywords = {HEMDIG FRAMEWORK, newspapers, History, Digitization, English newspapers, Library materials},
	file = {gooding_2017_historic newspapers in the digital age.pdf:/home/ebn/pCloudDrive/zot_library/Routledge, Taylor & Francis Group/2017/gooding_2017_historic newspapers in the digital age.pdf:application/pdf},
}

@article{gooding_mass_2013,
	title = {Mass digitization and the garbage dump: {The} conflicting needs of quantitative and qualitative methods},
	volume = {28},
	issn = {0268-1145, 1477-4615},
	shorttitle = {Mass digitization and the garbage dump},
	url = {https://academic.oup.com/dsh/article-lookup/doi/10.1093/llc/fqs054},
	doi = {10.1093/llc/fqs054},
	language = {en},
	number = {3},
	urldate = {2020-01-27},
	journal = {Literary and Linguistic Computing},
	author = {Gooding, P.},
	month = sep,
	year = {2013},
	keywords = {HEMDIG FRAMEWORK, google books, large-scale digitization, cultural heritage},
	pages = {425--431},
	file = {gooding_2013_mass digitization and the garbage dump.pdf:/home/ebn/pCloudDrive/zot_library/Literary and Linguistic Computing/2013/gooding_2013_mass digitization and the garbage dump.pdf:application/pdf},
}

@article{liebl_evaluation_2020,
	title = {An {Evaluation} of {DNN} {Architectures} for {Page} {Segmentation} of {Historical} {Newspapers}},
	url = {http://arxiv.org/abs/2004.07317},
	abstract = {One important and particularly challenging step in the optical character recognition (OCR) of historical documents with complex layouts, such as newspapers, is the separation of text from non-text content (e.g. page borders or illustrations). This step is commonly referred to as page segmentation. While various rule-based algorithms have been proposed, the applicability of Deep Neural Networks (DNNs) for this task recently has gained a lot of attention. In this paper, we perform a systematic evaluation of 11 different published DNN backbone architectures and 9 different tiling and scaling configurations for separating text, tables or table column lines. We also show the influence of the number of labels and the number of training pages on the segmentation quality, which we measure using the Matthews Correlation Coefficient. Our results show that (depending on the task) Inception-ResNet-v2 and EfficientNet backbones work best, vertical tiling is generally preferable to other tiling approaches, and training data that comprises 30 to 40 pages will be sufficient most of the time.},
	language = {en},
	urldate = {2022-01-29},
	journal = {arXiv:2004.07317 [cs]},
	author = {Liebl, Bernhard and Burghardt, Manuel},
	month = apr,
	year = {2020},
	note = {arXiv: 2004.07317},
	keywords = {HEMDIG FRAMEWORK, newspapers, OCR, page segmentation, deep neural networks},
	file = {arXiv.org Snapshot:/home/ebn/Zotero/storage/GGS42FM5/2004.html:text/html;liebl_burghardt_2020_an evaluation of dnn architectures for page segmentation of.pdf:/home/ebn/pCloudDrive/zot_library/arXiv2004.07317 [cs]/2020/liebl_burghardt_2020_an evaluation of dnn architectures for page segmentation of.pdf:application/pdf},
}

@article{butler_alts_2017,
	title = {Alts, {Abbreviations}, and {AKAs}: historical onomastic variation and automated named entity recognition},
	volume = {13},
	shorttitle = {Alts, {Abbreviations}, and {AKAs}},
	number = {1},
	journal = {Journal of Map \& Geography Libraries},
	author = {Butler, James O. and Donaldson, Christopher E. and Taylor, Joanna E. and Gregory, Ian N.},
	year = {2017},
	note = {Publisher: Taylor \& Francis},
	keywords = {HEMDIG FRAMEWORK, NER, gazetteers, GIS},
	pages = {58--81},
	file = {butleret al_2017_alts, abbreviations, and akas.pdf:/home/ebn/pCloudDrive/zot_library/Journal of Map & Geography Libraries/2017/butleret al_2017_alts, abbreviations, and akas.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/TYCIEWTQ/15420353.2017.html:text/html},
}

@inproceedings{byrne_nested_2007,
	title = {Nested named entity recognition in historical archive text},
	booktitle = {International {Conference} on {Semantic} {Computing} ({ICSC} 2007)},
	publisher = {IEEE},
	author = {Byrne, Kate},
	year = {2007},
	keywords = {HEMDIG FRAMEWORK, NER, relation extraction},
	pages = {589--596},
	file = {byrne_2007_nested named entity recognition in historical archive text.pdf:/home/ebn/pCloudDrive/zot_library/IEEE/2007/byrne_2007_nested named entity recognition in historical archive text.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/7I8RFWQZ/4338398.html:text/html},
}

@inproceedings{grover_named_2008,
	title = {Named {Entity} {Recognition} for {Digitised} {Historical} {Texts}.},
	booktitle = {{LREC}},
	author = {Grover, Claire and Givon, Sharon and Tobin, Richard and Ball, Julian},
	year = {2008},
	keywords = {HEMDIG FRAMEWORK, NER},
	file = {Full Text:/home/ebn/Zotero/storage/M7UFIGM9/Grover et al. - 2008 - Named Entity Recognition for Digitised Historical .pdf:application/pdf},
}

@inproceedings{vale_building_2008,
	title = {Building a large dictionary of abbreviations for named entity recognition in {Portuguese} historical corpora},
	author = {Vale, Oto and Candido, Arnaldo and Muniz, Marcelo and Bengtson, Clarissa and Cucatto, Lívia and Almeida, Gladis and Batista, Abner and Parreira, Maria C. and Biderman, Maria Tereza and Aluísio, Sandra},
	year = {2008},
	keywords = {HEMDIG FRAMEWORK, NER, portuguese},
	file = {Full Text:/home/ebn/Zotero/storage/H9GW2R3F/Vale et al. - 2008 - Building a large dictionary of abbreviations for n.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/8JAPIB84/hal-01110200.html:text/html},
}

@inproceedings{neudecker_open_2016,
	title = {An open corpus for named entity recognition in historic newspapers},
	booktitle = {Proceedings of the {Tenth} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC}'16)},
	author = {Neudecker, Clemens},
	year = {2016},
	keywords = {HEMDIG FRAMEWORK, newspapers, OCR, NER},
	pages = {4348--4352},
	file = {neudecker_2016_an open corpus for named entity recognition in historic.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2016/neudecker_2016_an open corpus for named entity recognition in historic.pdf:application/pdf},
}

@inproceedings{mac_kim_finding_2015,
	title = {Finding names in trove: named entity recognition for {Australian} historical newspapers},
	shorttitle = {Finding names in trove},
	booktitle = {Proceedings of the {Australasian} {Language} {Technology} {Association} {Workshop} 2015},
	author = {Mac Kim, Sunghwan and Cassidy, Steve},
	year = {2015},
	keywords = {HEMDIG FRAMEWORK, newspapers, NER, LOD, trove collection},
	pages = {57--65},
	file = {mac kim_cassidy_2015_finding names in trove.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2015/mac kim_cassidy_2015_finding names in trove.pdf:application/pdf},
}

@article{bloch_networks_2020,
	title = {Networks from archives: {Reconstructing} networks of official correspondence in the early modern {Portuguese} empire},
	issn = {0378-8733},
	shorttitle = {Networks from archives},
	url = {http://www.sciencedirect.com/science/article/pii/S0378873320300769},
	doi = {10.1016/j.socnet.2020.08.008},
	abstract = {Historical archives provide invaluable insights into societies of the past, including social networks. However, the required amount of traditional archival work makes historical network studies usually small-scaled. We consider the problem of processing a large corpus of unstructured textual information to extract network data. The corpus consists of almost 170,000 documents of administrative correspondence of the Portuguese Empire, from 1610 to 1833, catalogued in the Portuguese Overseas Archives of Lisbon. Our contribution is twofold: the method and the result. Firstly, grounded in the review of manual, semi-manual and automatic methods of network data extraction from natural language corpora, we propose and demonstrate an approach using modern natural language processing algorithms. This approach tries to mimic traditional archivist’s coding practices and is applicable to large corpora of texts, for which manual coding is infeasible because of scale. We believe our approach is generic and adaptable to other substantive contexts, languages, and types of historical archives. Secondly, the dataset created is rich in additional information such as occupation, administrative affiliation, and geographical location of senders and recipients. We provide a preliminary network analysis suggesting that the dataset is an attractive material for historians and social network researchers for addressing research questions about the political and social evolution of the early modern Portuguese Empire, spanning the reign of seven Portuguese monarchs.},
	language = {en},
	urldate = {2020-09-25},
	journal = {Social Networks},
	author = {Błoch, Agata and Vasques Filho, Demival and Bojanowski, Michał},
	month = sep,
	year = {2020},
	keywords = {HEMDIG FRAMEWORK, NER, Digital humanities, Natural language processing, NLP, portuguese, Colonial studies, Correspondence networks, Early modern letters, Historical network research, Portuguese empire},
	file = {błoch_et_al_2020_networks_from_archives.pdf:/home/ebn/pCloudDrive/zot_library/Social Networks/2020/błoch_et_al_2020_networks_from_archives.pdf:application/pdf;ScienceDirect Snapshot:/home/ebn/Zotero/storage/VMVVY2IQ/S0378873320300769.html:text/html},
}

@article{gooding_myth_2013,
	title = {The myth of the new: mass digitization, distant reading, and the future of the book},
	volume = {28},
	issn = {0268-1145},
	shorttitle = {The myth of the new},
	url = {http://eprints.gla.ac.uk/168419/},
	doi = {http://dx.doi.org/10.1093/llc/fqt051},
	abstract = {This article presents the theoretical background to a wider project that is attempting to increase our understanding of the impact and uses of large-scale digitization, being undertaken by the first author at University College London with the working title ‘What is the impact of large-scale digitization upon researchers and the information sector?’ It discusses the controversy surrounding the emergence of mass digitization: the creation and collection of huge resources containing millions of pages of textual cultural content. It demonstrates that the polarized nature of the literature about this technological development is far from unprecedented, and in fact can be traced through the theory of a number of varied fields: the debate surrounding mechanization and digital technologies, our understanding of the role of the sublime in modern representations of technology, the similarities between the sociology of city life and digital information overload, and the way in which innovations are diffused throughout society. It proposes that these theories explain why debates around technological innovation often become so hyperbolic, creating an almost mythological view of technological determination. It concludes that, as a result of the processes outlined in this theory, mass digitization has become stuck between two conflicting rhetorical movements, and that it is therefore necessary to begin working to increase our understanding of this technology and to move the debate onwards using evidence from the real world.},
	language = {en},
	number = {4},
	urldate = {2020-01-27},
	journal = {Literary and Linguistic Computing},
	author = {Gooding, Paul and Terras, Melissa and Warwick, Claire},
	month = dec,
	year = {2013},
	keywords = {HEMDIG FRAMEWORK, large-scale digitization, distant reading},
	pages = {629--639},
	file = {goodinget al_2013_the myth of the new.pdf:/home/ebn/pCloudDrive/zot_library/Literary and Linguistic Computing/2013/goodinget al_2013_the myth of the new.pdf:application/pdf},
}

@article{ehrmann_named_2021,
	title = {Named {Entity} {Recognition} and {Classification} on {Historical} {Documents}: {A} {Survey}},
	shorttitle = {Named {Entity} {Recognition} and {Classification} on {Historical} {Documents}},
	url = {http://arxiv.org/abs/2109.11406},
	abstract = {After decades of massive digitisation, an unprecedented amount of historical documents is available in digital format, along with their machine-readable texts. While this represents a major step forward with respect to preservation and accessibility, it also opens up new opportunities in terms of content mining and the next fundamental challenge is to develop appropriate technologies to efficiently search, retrieve and explore information from this 'big data of the past'. Among semantic indexing opportunities, the recognition and classification of named entities are in great demand among humanities scholars. Yet, named entity recognition (NER) systems are heavily challenged with diverse, historical and noisy inputs. In this survey, we present the array of challenges posed by historical documents to NER, inventory existing resources, describe the main approaches deployed so far, and identify key priorities for future developments.},
	urldate = {2022-03-19},
	journal = {arXiv:2109.11406 [cs]},
	author = {Ehrmann, Maud and Hamdi, Ahmed and Pontes, Elvys Linhares and Romanello, Matteo and Doucet, Antoine},
	month = sep,
	year = {2021},
	note = {arXiv: 2109.11406},
	keywords = {HEMDIG FRAMEWORK, NER, historical documents, NLP},
	file = {arXiv.org Snapshot:/home/ebn/Zotero/storage/W6D6X4Q5/2109.html:text/html;ehrmannet al_2021_named entity recognition and classification on historical.pdf:/home/ebn/pCloudDrive/zot_library/arXiv2109.11406 [cs]/2021/ehrmannet al_2021_named entity recognition and classification on historical.pdf:application/pdf},
}

@article{late_interacting_2021,
	title = {Interacting with digitised historical newspapers: understanding the use of digital surrogates as primary sources},
	volume = {78},
	issn = {0022-0418},
	shorttitle = {Interacting with digitised historical newspapers},
	url = {https://doi.org/10.1108/JD-04-2021-0078},
	doi = {10.1108/JD-04-2021-0078},
	abstract = {Purpose The paper examines academic historians' information interactions with material from digital historical-newspaper collections as the research process unfolds. Design/methodology/approach The study employed qualitative analysis from in-depth interviews with Finnish history scholars who use digitised historical newspapers as primary sources for their research. A model for task-based information interaction guided the collection and analysis of data. Findings The study revealed numerous information interactions within activities related to task-planning, the search process, selecting and working with the items and synthesis and reporting. The information interactions differ with the activities involved, which call for system support mechanisms specific to each activity type. Various activities feature information search, which is an essential research method for those using digital collections in the compilation and analysis of data. Furthermore, application of quantitative methods and multidisciplinary collaboration may be shaping culture in history research toward convergence with the research culture of the natural sciences. Originality/value For sustainable digital humanities infrastructure and digital collections, it is of great importance that system designers understand how the collections are accessed, why and their use in the real-world context. The study enriches understanding of the collections' utilisation and advances a theoretical framework for explicating task-based information interaction.},
	number = {7},
	urldate = {2022-03-19},
	journal = {Journal of Documentation},
	author = {Late, Elina and Kumpulainen, Sanna},
	month = jan,
	year = {2021},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Digital libraries, HEMDIG FRAMEWORK, newspapers, History, Task analysis, Behaviour, Task based information interaction, user studies},
	pages = {106--124},
	file = {late_kumpulainen_2021_interacting with digitised historical newspapers.pdf:/home/ebn/pCloudDrive/zot_library/Journal of Documentation/2021/late_kumpulainen_2021_interacting with digitised historical newspapers.pdf:application/pdf},
}

@article{oberbichler_topic-specific_2021,
	title = {Topic-specific corpus building: {A} step towards a representative newspaper corpus on the topic of return migration using text mining methods},
	shorttitle = {Topic-specific corpus building},
	url = {https://journalofdigitalhistory.org/en/article/4yxHGiqXYRbX},
	doi = {https://doi.org/10.1515/JDH-2021-1003?locatt=label:JDHFULL},
	abstract = {Humanities researchers often encounter the problem that their specialized corpora, created by keyword searches, either contain documents that are irrelevant...},
	language = {En},
	number = {jdh001},
	urldate = {2022-03-19},
	journal = {Journal of Digital history},
	author = {Oberbichler, Sarah and Pfanzelter, Eva},
	month = oct,
	year = {2021},
	note = {Publisher: DeGruyter
Section: jdh001},
	keywords = {HEMDIG FRAMEWORK, newspapers, text mining, corpus building, similarity},
}

@book{galloway_interface_2012,
	address = {Cambridge},
	title = {The {Interface} {Effect}},
	isbn = {978-0-7456-6253-4},
	abstract = {Interfaces are back, or perhaps they never left. The familiar Socratic conceit from the Phaedrus, of communication as the process of writing directly on the soul of the other, has returned to center stage in today's discussions of culture and media. Indeed Western thought has long construed media as a grand choice between two kinds of interfaces. Following the optimistic path, media seamlessly interface self and other in a transparent and immediate connection. But, following the pessimistic path, media are the obstacles to direct communion, disintegrating self and other into misunderstanding and contradiction. In other words, media interfaces are either clear or complicated, either beautiful or deceptive, either already known or endlessly interpretable. Recognizing the limits of either path, Galloway charts an alternative course by considering the interface as an autonomous zone of aesthetic activity, guided by its own logic and its own ends: the interface effect. Rather than praising user-friendly interfaces that work well, or castigating those that work poorly, this book considers the unworkable nature of all interfaces, from windows and doors to screens and keyboards. Considered allegorically, such thresholds do not so much tell the story of their own operations but beckon outward into the realm of social and political life, and in so doing ask a question to which the political interpretation of interfaces is the only coherent answer. Grounded in philosophy and cultural theory and driven by close readings of video games, software, television, painting, and other images, Galloway seeks to explain the logic of digital culture through an analysis of its most emblematic and ubiquitous manifestation –  the interface.},
	language = {en},
	publisher = {Polity},
	author = {Galloway, Alexander R.},
	month = oct,
	year = {2012},
	keywords = {Computers / Information Technology, Computers / Social Aspects, GUI, HEMDIG FRAMEWORK, Social Science / Media Studies},
}

@article{brasil_pyhdb_2022,
	title = {{pyHDB} - {Ferramenta} {Heurística} para a {Hemeroteca} {Digital} {Brasileira}: utilizando técnicas de web scraping para a pesquisa em {História}},
	volume = {15},
	issn = {1983-9928},
	shorttitle = {{pyHDB} - {Ferramenta} {Heurística} para a {Hemeroteca} {Digital} {Brasileira}},
	doi = {10.15848/hh.v15i40.1904},
	abstract = {Esse artigo tem como objetivo analisar a relação entre ferramentas e interfaces de busca em repositórios de fontes digitais e a construção do conhecimento histórico na era digital. Para tanto, analiso a pyHDB:Ferramenta Heurística para a Hemeroteca Digital Brasileira da Biblioteca Nacional, caracterizando seus aspectos técnicos, metodológicos e heurísticos. Tal ferramenta é um programa de computador escrito com a linguagem de programação Python e utiliza técnicas de web scraping. Possui o objetivo de auxiliar pesquisadores no processo de construção e registro metodológico, criando relatórios, dados tabulares e datasets a partir dos parâmetros de busca definidos. Primeiramente, analiso de forma crítica os resultados originados pela interface gráfica da Hemeroteca Digital Brasileira. Em seguida, apresento detalhadamente a pyHDB, tanto seus aspectos éticos e técnicos quanto possibilidades analíticas, através de três exemplos de busca. Por fim, proponho algumas considerações finais acerca das vantagens do desenvolvimento e uso de ferramentas metodológicas digitais para a pesquisa histórica.},
	language = {pt-BR},
	number = {40},
	journal = {História da Historiografia: International Journal of Theory and History of Historiography},
	author = {Brasil, Eric},
	year = {2022},
	keywords = {data mining, data visualization, HDB, HEMDIG FRAMEWORK, Heurística, História Digital, Metodologia da história, newspapers, python},
	file = {brasil_2022_pyhdb - ferramenta heurística para a hemeroteca digital.pdf:/home/ebn/pCloudDrive/zot_library/História da Historiografia International Journal of Theory and History of Historiography/2022/brasil_2022_pyhdb - ferramenta heurística para a hemeroteca digital.pdf:application/pdf},
}

@article{zhu_docbed_2022,
	title = {{DocBed}: {A} {Multi}-{Stage} {OCR} {Solution} for {Documents} with {Complex} {Layouts}},
	volume = {36},
	copyright = {Copyright (c) 2022 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	shorttitle = {{DocBed}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/21539},
	doi = {10.1609/aaai.v36i11.21539},
	abstract = {Digitization of newspapers is of interest for many reasons including preservation of history, accessibility and search ability, etc. While digitization of documents such as scientific articles and magazines is prevalent in literature, one of the main challenges for digitization of newspaper lies in its complex layout (e.g. articles spanning multiple columns, text interrupted by images) analysis, which is necessary to preserve human read-order. This work provides a major breakthrough in the digitization of newspapers on three fronts: first, releasing a dataset of 3000 fully-annotated, real-world newspaper images from 21 different U.S. states representing an extensive variety of complex layouts for document layout analysis; second, proposing layout segmentation as a precursor to existing optical character recognition (OCR) engines, where multiple state-of-the-art image segmentation models and several post-processing methods are explored for document layout segmentation; third, providing a thorough and structured evaluation protocol for isolated layout segmentation and end-to-end OCR.},
	language = {en},
	number = {11},
	urldate = {2023-05-29},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Zhu, Wenzhen and Sokhandan, Negin and Yang, Guang and Martin, Sujitha and Sathyanarayana, Suchitra},
	month = jun,
	year = {2022},
	note = {Number: 11},
	keywords = {HEMDIG FRAMEWORK, Historical Document Processing},
	pages = {12643--12649},
	file = {zhu et al_2022_docbed.pdf:/home/ebn/pCloudDrive/zot_library/Proceedings of the AAAI Conference on Artificial Intelligence/2022/zhu et al_2022_docbed.pdf:application/pdf},
}

@article{talboom_keeping_2022,
	title = {Keeping it under lock and keywords: exploring new ways to open up the web archives with notebooks},
	volume = {22},
	issn = {1573-7500},
	shorttitle = {Keeping it under lock and keywords},
	url = {https://doi.org/10.1007/s10502-022-09391-6},
	doi = {10.1007/s10502-022-09391-6},
	abstract = {The UK Government Web Archive (UKGWA) has been archiving government websites since 1996 and now holds regular snapshots of over 5000 sites. Currently, this material can be accessed through browsing or a simple keyword search interface on their website and has also been catalogued in The National Archives’ online catalogue, Discovery. However, the scale of the UKGWA exposes the limits of the current search interface, and there is no facility to understand the archive in aggregate. This article seeks to go beyond the simple keyword search by exploring the data sources available, from APIs to web crawling, for computational analysis of the UKGWA. The article is accompanied by two Python Notebooks which present examples of analysis using each data source. Notebooks lower the technical barriers for the reader to explore and interpret the UKGWA as data, while surfacing the challenges around making web material computationally accessible.},
	language = {en},
	number = {3},
	urldate = {2023-05-30},
	journal = {Archival Science},
	author = {Talboom, Leontien and Bell, Mark},
	month = sep,
	year = {2022},
	keywords = {Access, Computational archival science, Digital archiving, Finding aids, HEMDIG FRAMEWORK, Notebooks, Web archives},
	pages = {393--415},
	file = {talboom_bell_2022_keeping it under lock and keywords.pdf:/home/ebn/pCloudDrive/zot_library/Archival Science/2022/talboom_bell_2022_keeping it under lock and keywords.pdf:application/pdf},
}

@misc{noauthor_ocr-d_nodate,
	title = {The {OCR}-{D} project - {OCR}-{D}},
	url = {https://ocr-d.de/en/about.html},
	urldate = {2023-08-02},
	keywords = {HEMDIG FRAMEWORK},
	file = {The OCR-D project - OCR-D:/home/ebn/Zotero/storage/B6GNK6QB/about.html:text/html},
}

@article{wilson_black_creating_2023,
	title = {Creating specialized corpora from digitized historical newspaper archives: {An} iterative bootstrapping approach},
	volume = {38},
	issn = {2055-7671},
	shorttitle = {Creating specialized corpora from digitized historical newspaper archives},
	url = {https://doi.org/10.1093/llc/fqac079},
	doi = {10.1093/llc/fqac079},
	abstract = {The availability of large digital archives of historical newspaper content has transformed the historical sciences. However, the scale of these archives can limit the direct application of advanced text processing methods. Even if it is computationally feasible to apply sophisticated language processing to an entire digital archive, if the material of interest is a small fraction of the archive, the results are unlikely to be useful. Methods for generating smaller specialized corpora from large archives are required to solve this problem. This article presents such a method for historical newspaper archives digitized using the METS/ALTO XML standard (Veridian Software, n.d.). The method is an ‘iterative bootstrapping’ approach in which candidate corpora are evaluated using text mining techniques, items are manually labelled, and Naïve Bayes text classifiers are trained and applied in order to produce new candidate corpora. The method is illustrated by a case study that investigates philosophical content, broadly construed, in pre-1900 English-language New Zealand newspapers. Extensive code is provided in Supplementary Materials.},
	number = {2},
	urldate = {2023-08-07},
	journal = {Digital Scholarship in the Humanities},
	author = {Wilson Black, Joshua},
	month = jun,
	year = {2023},
	keywords = {HEMDIG FRAMEWORK},
	pages = {779--797},
	file = {Snapshot:/home/ebn/Zotero/storage/M9EURASQ/6957053.html:text/html;wilson black_2023_creating specialized corpora from digitized historical.pdf:/home/ebn/pCloudDrive/zot_library/Digital Scholarship in the Humanities/2023/wilson black_2023_creating specialized corpora from digitized historical.pdf:application/pdf},
}

@article{dzhukaeva_digital_2023,
	title = {Digital {Technology} and {Practices} of {Humanities} {Research}},
	volume = {172},
	copyright = {© The Authors, published by EDP Sciences, 2023},
	issn = {2261-2424},
	url = {https://www.shs-conferences.org/articles/shsconf/abs/2023/21/shsconf_shcms2023_05001/shsconf_shcms2023_05001.html},
	doi = {10.1051/shsconf/202317205001},
	abstract = {Our world began with an image. A leaf falls from a tree and lands on the surface of the water, carried by ripples and whirlpools to a new place far removed from ins origin. There is he able to form new streams in calm water. This image is a metaphor, representing the interweaving of technology with the practices and values of humanities research, being both a point of intersection and a torrent of unexpected and predictable contingencies. Logical methods in the digital humanities lend themselves well to theory and documentation. At a level of a distinct set of defined statistical topics that can be generated using a software tool such as MALLET (Machine Learning for Language toolkit, a cross – platform topic modeling tool) rather that a set equivalent retrieved a linear normal reading process, representing the difference in degree. The methodological stake and consequences of the choice for the knowledge it creates are questioned, but taken into account and understood in scientific discussions. The falling leaf, getting into the wave, continues to move down, and the open frame of its fall can be lost, changing the path of the leaf. However, the leaf may later grow together, thus forming a barrier that affects further flows. Technology is sublimated into the fabric of scientific methods and the organization of the work of scientists is marked by a certain inevitability because of the methodological forces at work and because of the technologies that enable communication and interaction in the wide society.},
	language = {en},
	urldate = {2023-08-07},
	journal = {SHS Web of Conferences},
	author = {Dzhukaeva, M. A. and Muslimova, M. I. and Mamedova, G. B.},
	year = {2023},
	note = {Publisher: EDP Sciences},
	keywords = {HEMDIG FRAMEWORK},
	pages = {05001},
	file = {dzhukaeva et al_2023_digital technology and practices of humanities research.pdf:/home/ebn/pCloudDrive/zot_library/SHS Web of Conferences/2023/dzhukaeva et al_2023_digital technology and practices of humanities research.pdf:application/pdf},
}

@misc{during_impresso_2023,
	title = {impresso {Text} {Reuse} at {Scale} impresso {Text} {Reuse} at {Scale}. {A} {Prototype} {Interface} for the {Exploration} of {Text} {Reuse} {Data} in {Semantically} {Enriched} {Historical} {Newspapers}},
	url = {https://www.researchgate.net/publication/372588607_impresso_Text_Reuse_at_Scale_impresso_Text_Reuse_at_Scale_A_Prototype_Interface_for_the_Exploration_of_Text_Reuse_Data_in_Semantically_Enriched_Historical_Newspapers},
	urldate = {2023-08-07},
	author = {Düring, Marten and Romanello, Matteo and Ehrmann, Maud and Beelen, Kaspar and Guido, Daniele and Deseure, Brecht and Bunout, Estelle and Keck, Jana and Apostolopoulos, Petros},
	month = jul,
	year = {2023},
	keywords = {HEMDIG FRAMEWORK},
	file = {düring et al_2023_impresso text reuse at scale impresso text reuse at scale.pdf:/home/ebn/pCloudDrive/zot_library/undefined/2023/düring et al_2023_impresso text reuse at scale impresso text reuse at scale.pdf:application/pdf},
}

@incollection{bunout_contextualising_2022,
	title = {Contextualising {Queries}: {Guidance} for {Research} using {Current} {Collections} of {Digitised} {Newspapers}},
	copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
	isbn = {978-3-11-072921-4},
	shorttitle = {Contextualising {Queries}},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110729214-013/html},
	abstract = {Contextualising Queries: Guidance for Research using Current Collections of Digitised Newspapers was published in Digitised Newspapers – A New Eldorado for Historians? on page 275.},
	language = {en},
	urldate = {2023-08-08},
	booktitle = {Contextualising {Queries}: {Guidance} for {Research} using {Current} {Collections} of {Digitised} {Newspapers}},
	publisher = {De Gruyter Oldenbourg},
	author = {Bunout, Estelle},
	month = dec,
	year = {2022},
	doi = {10.1515/9783110729214-013},
	keywords = {HEMDIG FRAMEWORK},
	pages = {275--300},
	file = {bunout_2022_contextualising queries.pdf:/home/ebn/pCloudDrive/zot_library/De Gruyter Oldenbourg/2022/bunout_2022_contextualising queries.pdf:application/pdf},
}

@article{koolen_toward_2019,
	title = {Toward a model for digital tool criticism: {Reflection} as integrative practice},
	volume = {34},
	issn = {2055-7671},
	shorttitle = {Toward a model for digital tool criticism},
	url = {https://doi.org/10.1093/llc/fqy048},
	doi = {10.1093/llc/fqy048},
	abstract = {In the past decade, an increasing set of digital tools has been developed with which digital sources can be selected, analyzed, and presented. Many tools go beyond key word search and perform different types of analysis, aggregation, mapping, and linking of data selections, which transforms materials and creates new perspectives, thereby changing the way scholars interact with and perceive their materials. These tools, together with the massive amount of digital and digitized data available for humanities research, put a strain on traditional humanities research methods. Currently, there is no established method of assessing the role of digital tools in the research trajectory of humanities scholars. There is no consensus on what questions researchers should ask themselves to evaluate digital sources beyond those of traditional analogue source criticism. This article aims to contribute to a better understanding of digital tools and the discussion of how to evaluate and incorporate them in research, based on findings from a digital tool criticism workshop held at the 2017 Digital Humanities Benelux conference. The overall goal of this article is to provide insight in the actual use and practice of digital tool criticism, offer a ready-made format for a workshop on digital tool criticism, give insight in aspects that play a role in digital tool criticism, propose an elaborate model for digital tool criticism that can be used as common ground for further conversations in the field, and finally, provide recommendations for future workshops, researchers, data custodians, and tool builders.},
	number = {2},
	urldate = {2023-08-08},
	journal = {Digital Scholarship in the Humanities},
	author = {Koolen, Marijn and van Gorp, Jasmijn and van Ossenbruggen, Jacco},
	month = jun,
	year = {2019},
	keywords = {HEMDIG FRAMEWORK},
	pages = {368--385},
	file = {koolen et al_2019_toward a model for digital tool criticism.pdf:/home/ebn/pCloudDrive/zot_library/Digital Scholarship in the Humanities/2019/koolen et al_2019_toward a model for digital tool criticism.pdf:application/pdf;Snapshot:/home/ebn/Zotero/storage/BPHG8FFZ/5127711.html:text/html},
}

@article{ehrmann_historical_nodate,
	title = {Historical {Newspaper} {User} {Interfaces}: {A} {Review}},
	abstract = {After decades of large-scale digitization, many historical newspaper collections are just one click away via online portals developed and supported by various public or private stakeholders. Initially offering access to full text search and facsimiles visualization only, historic newspaper user interfaces are increasingly integrating advanced exploration features based on the application of text mining tools to digitized sources. As gateways to enriched material, such interfaces are however not neutral and play a fundamental role in how users perceive historical sources, understand potential biases of upstream processes and benefit from the opportunities of datafication. What features can be found in current interfaces, and to what degree do interfaces adopt novel technologies? This paper presents a survey of interfaces for digitized historical newspapers with the aim of mapping the current state of the art and identifying recent trends with regard to content presentation, enrichment and user interaction. We devised 6 interface assessment criteria and reviewed twenty-four interfaces based on ca. 140 predefined features.},
	language = {en},
	author = {Ehrmann, Maud},
	keywords = {HEMDIG FRAMEWORK},
	file = {Ehrmann - Historical Newspaper User Interfaces A Review.pdf:/home/ebn/Zotero/storage/YE9U9Z3Y/Ehrmann - Historical Newspaper User Interfaces A Review.pdf:application/pdf},
}
