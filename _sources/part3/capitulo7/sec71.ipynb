{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1. Relatórios Metodológicos para Pesquisa em Interfaces Gráficas de Periódicos Digitalizados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com esse notebook, você pode registrar os parâmetros e metadados de pesquisas realizadas em interfaces de busca de periódicos digitalizados. O objetivo é facilitar a replicação de pesquisas, garantir transparência metodológica, comparação de resultados e o próprio processo de análise e escrita."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como usar\n",
    "\n",
    "Explicações retiradas de Melanie Walsh, Introduction to Cultural Analytics & Python, Version 1 (2021), https://doi.org/10.5281/zenodo.4411250.\n",
    "\n",
    "> Open Jupyter Notebook in the Cloud\n",
    "> \n",
    "> You can open most pages from this book in the cloud and run the code live. Hover over the rocket icon at the top of the page and click “Binder” to open a version of the same page in the cloud.\n",
    "> Binder is a service that allows you to run Jupyter notebooks without any prior configuration or installation. It may take a few minutes for the Jupyter notebook to load, so be patient.\n",
    ">\n",
    "> Download Jupyter Notebook\n",
    "> \n",
    "> You can download any Jupyter notebook page from this book as a Jupyter notebook file (.ipynb). Hover over the download icon and click “.ipynb”\n",
    "> \n",
    "> Attention\n",
    "> \n",
    "> To work with this .ipynb file, you will need to have Jupyter installed and running on your own computer.\n",
    "> \n",
    "> Download PDF\n",
    "> \n",
    "> You can download any Jupyter notebook page from this book as a PDF file. Hover over the download icon and click “.pdf”\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalar bibliotecas\n",
    "\n",
    "A biblioteca pandas será necessária para juntar diferentes arquivos csv. Como ela não é nativa do Python, é preciso instalá-la. O jupyter notebook nos permite instalar bibliotecas diretamente no notebook. Para isso, basta executar o comando pip, precedido do sinal de porcentagem (%), seguido do nome da biblioteca que se deseja instalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando a biblioteca pandas\n",
    "%pip install pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar bibliotecas\n",
    "\n",
    "Aqui importamos as bibliotecas necessárias para a execução do código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "import csv # Biblioteca para manipulação de arquivos csv\n",
    "import datetime # Biblioteca para manipulação de datas\n",
    "import os # Biblioteca para manipulação do sistema operacional\n",
    "import pandas as pd # Biblioteca para manipulação de dataframes\n",
    "import pathlib # Biblioteca para manipulação de diretórios"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Dica\n",
    ":class: hint\n",
    "Esta célula só precisa ser executada uma vez.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação inicial: criação do diretório geral e coleta de dados sobre o repositório\n",
    "\n",
    "Vamos criar um diretório para armazenamento dos relatórios. Em seguida coletamos as informações sobre o nome do repositório, sua URL base para pesquisa e nome do usuário que realiza a pesquisa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a pasta \"reports\" se ela não existir\n",
    "pathlib.Path(\"reports\").mkdir(exist_ok=True)\n",
    "\n",
    "# Coleta nome do repositório e nome do usuário\n",
    "repo_name = input(\"Informe o nome do repositório: \")\n",
    "repo_url = input(\"Informe a URL do repositório: \")\n",
    "user_name = input(\"Informe seu nome: \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Dica\n",
    ":class: hint\n",
    "A célula anterior, só precisa ser executada uma vez para cada repositório. Caso você realize diversas pesquisas em um mesmo repositório, basta repetir as células abaixo para cada pesquisa.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeira parte: coleta de dados gerais\n",
    "\n",
    "Essa etapa cria o arquivo de metadados da pesquisa. Esse arquivo será usado para armazenar todos os dados coletados durante a pesquisa. \n",
    "\n",
    "Nessa primeira etapa o arquivo é criado, e os dados sobre data, hora, nome do usuário, nome do repositório e URL base são armazenados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Dica\n",
    ":class: hint\n",
    "As etapas 1, 2 e 3 devem ser executadas para cada conjunto de parâmetros de pesquisa em um mesmo repositório.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria hora e data da execução\n",
    "now = datetime.datetime.now()\n",
    "search_time = now.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "# Cria o nome do arquivo de texto de saída\n",
    "file_name = f\"{repo_name}_{search_time}.txt\"\n",
    "\n",
    "# cria o caminho completo do arquivo\n",
    "file_path = pathlib.Path(\"reports\") / repo_name / file_name\n",
    "\n",
    "# Cria a pasta com o nome do repositório se ela não existir\n",
    "file_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "# Cria o arquivo e escreve os dados gerais da pesquisa\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(\"Dados gerais da pesquisa\\n\")\n",
    "    f.write(f\"Nome do repositório: {repo_name}\\n\")\n",
    "    f.write(f\"URL do repositório: {repo_url}\\n\")\n",
    "    f.write(f\"Nome do usuário: {user_name}\\n\")\n",
    "    f.write(f\"Data: {now.strftime('%Y-%m-%d')}\\n\")\n",
    "    f.write(f\"Hora: {now.strftime('%H:%M:%S')}\\n\")\n",
    "\n",
    "print(f\"Arquivo {file_path} criado com sucesso!\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segunda parte: parâmetros da pesquisa\n",
    "\n",
    "Nessa etapa, vamos coletar os parâmetros da pesquisa. Esses parâmetros são: local, data, palavra-chave, descrição breve, e outros.\n",
    "\n",
    "Esses dados são incluídos no arquivo de texto criado na primeira etapa.\n",
    "\n",
    "Também é criado um arquivo csv com os mesmos dados, para facilitar a visualização e análise dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciona os parâmetros da pesquisa ao arquivo\n",
    "with open(file_path, \"a\") as f:\n",
    "    # Pede os parâmetros da pesquisa\n",
    "    print(\"Informe os parâmetros da pesquisa, conforme solicitado.\\n\\\n",
    "    Caso não tenha um parâmetro específico, deixe o campo vazio.\\n\")\n",
    "    local = input(\"Informe o parâmetro para local: \")\n",
    "    data = input(\"Informe o parâmetro para data: \")\n",
    "    palavra_chave = input(\"Informe os termos utilizados na pesquisa: \")\n",
    "    resumo = input(\"Escreva um breve resumo para esse conjunto de parâmetros: \")\n",
    "    \n",
    "    # Escreve os parâmetros no arquivo\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(\"Parâmetros da pesquisa\\n\")\n",
    "    f.write(f\"Resumo da pesquisa: {resumo}\\n\")\n",
    "    f.write(f\"Local: {local}\\n\")\n",
    "    f.write(f\"Recorte temporal: {data}\\n\")\n",
    "    f.write(f\"Termos pesquisados: {palavra_chave}\\n\")\n",
    "\n",
    "    # Cria o arquivo CSV com os dados\n",
    "    csv_file_name = file_name.replace(\".txt\", \".csv\")\n",
    "    csv_file_path = pathlib.Path(\"reports\") / repo_name / csv_file_name\n",
    "    csv_file_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "    with open(csv_file_path, \"w\", newline=\"\") as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow([\"Repositório\", \"URL\", \"Usuário\", \"Data da pesquisa\", \"Resumo da pesquisa\", \"Local\", \"Recorte temporal\", \"Termos pesquisados\"])\n",
    "        writer.writerow([repo_name, repo_url, user_name, search_time, resumo, local, data, palavra_chave])\n",
    "print(\"Parâmetros da pesquisa adicionados ao arquivo!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terceira parte: registro dos resultados\n",
    "\n",
    "Aqui, coletamos os dados sobre os resultados da pesquisa. Esses dados são: link da página de resultados e número total de ocorrências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pede os dados sobre os resultados\n",
    "result_link = input(\"Informe o link da página com resultados da busca: \")\n",
    "result_number = input(\"Informe o número de ocorrências encontrados: \")\n",
    "\n",
    "# Adiciona os dados no CSV como novas colunas ao lado dos parâmetros da pesquisa\n",
    "with open(csv_file_path, \"r\") as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    rows = list(reader)\n",
    "    rows[0].extend([\"Link da página com resultados da busca\", \"Número de ocorrências encontrados\"])\n",
    "    rows[1].extend([result_link, result_number])\n",
    "\n",
    "# Reescreve o arquivo CSV com os novos dados\n",
    "with open(csv_file_path, \"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "# Adiciona os dados no arquivo TXT\n",
    "with open(file_path, \"a\") as f:\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(\"Resultados da pesquisa\\n\")\n",
    "    f.write(f\"Link da página com resultados da busca: {result_link}\\n\")\n",
    "    f.write(f\"Número de ocorrências encontradas: {result_number}\\n\")\n",
    "    \n",
    "print(\"Resultados da pesquisa adicionados ao arquivo!\")    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quarta parte: Concatenar arquivos CSV\n",
    "\n",
    "Nessa etapa, temos a opção de concatenar todos os arquivos csv que estão no diretório de rseultados de um mesmo periódico. Isso facilita a visualização, recuperação e análise dos dados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Dica\n",
    ":class: hint\n",
    "É recomendável que essa etapa seja realizada ao final de um conjunto de pesquisas em um mesmo periódico. Assim, após reunir uma série de arquivos csv, podemos concatená-los e obter um único arquivo com todos os dados.\\\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pergunta se o usuário deseja concatenar os arquivos CSV\n",
    "concatenate_csv = input(\"Deseja concatenar todos os arquivos CSV existentes na pasta? (S/N) \")\n",
    "\n",
    "# Se a resposta for sim, concatena os arquivos\n",
    "if concatenate_csv.upper() == \"S\":\n",
    "    csv_files = [f for f in os.listdir(f\"reports/{repo_name}\") if f.endswith(\".csv\")]\n",
    "    if len(csv_files) > 1:\n",
    "        df = pd.concat([pd.read_csv(os.path.join(f\"reports/{repo_name}\", f)) for f in csv_files])\n",
    "        concatenated_csv_file_path = pathlib.Path(\"reports\") / repo_name / f\"{repo_name}_concatenated.csv\"\n",
    "        df.to_csv(concatenated_csv_file_path, index=False)\n",
    "        print(f\"Arquivo com todos os dados concatenados criado em {concatenated_csv_file_path}.\")\n",
    "    else:\n",
    "        print(\"Não há arquivos CSV suficientes para concatenar.\")\n",
    "# Se a resposta for não, encerra o programa\n",
    "else:\n",
    "    print(\"Operação de concatenação cancelada pelo usuário.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
